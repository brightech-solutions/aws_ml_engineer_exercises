{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# SageMaker Image Classification Exercise\n",
    "\n",
    "This notebook demonstrates Amazon SageMaker's **Image Classification** algorithm for classifying images into categories.\n",
    "\n",
    "## What You'll Learn\n",
    "1. How to prepare image data for classification\n",
    "2. How to train an image classifier with transfer learning\n",
    "3. How to interpret classification predictions\n",
    "\n",
    "## What is Image Classification?\n",
    "\n",
    "Image Classification assigns one or more labels to an entire image. Unlike object detection, it doesn't localize objects.\n",
    "\n",
    "**SageMaker provides two implementations:**\n",
    "- **MXNet-based**: CNN with ResNet architecture\n",
    "- **TensorFlow-based**: Transfer learning from TensorFlow Hub models\n",
    "\n",
    "## Use Cases\n",
    "\n",
    "| Industry | Application |\n",
    "|----------|-------------|\n",
    "| E-commerce | Product categorization |\n",
    "| Healthcare | Medical image diagnosis |\n",
    "| Manufacturing | Defect detection |\n",
    "| Social Media | Content moderation |\n",
    "| Agriculture | Plant disease identification |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Step 1: Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.image_uris import retrieve\n",
    "from sagemaker.estimator import Estimator\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Configure AWS session from environment variables\n",
    "aws_profile = os.getenv('AWS_PROFILE')\n",
    "aws_region = os.getenv('AWS_REGION', 'us-west-2')\n",
    "sagemaker_role = os.getenv('SAGEMAKER_ROLE_ARN')\n",
    "\n",
    "if aws_profile:\n",
    "    boto3.setup_default_session(profile_name=aws_profile, region_name=aws_region)\n",
    "else:\n",
    "    boto3.setup_default_session(region_name=aws_region)\n",
    "\n",
    "# SageMaker session and role\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "if sagemaker_role:\n",
    "    role = sagemaker_role\n",
    "else:\n",
    "    role = get_execution_role()\n",
    "\n",
    "region = sagemaker_session.boto_region_name\n",
    "\n",
    "print(f\"AWS Profile: {aws_profile or 'default'}\")\n",
    "print(f\"SageMaker Role: {role}\")\n",
    "print(f\"Region: {region}\")\n",
    "print(f\"SageMaker SDK Version: {sagemaker.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "BUCKET_NAME = sagemaker_session.default_bucket()\n",
    "PREFIX = \"image-classification\"\n",
    "\n",
    "print(f\"S3 Bucket: {BUCKET_NAME}\")\n",
    "print(f\"S3 Prefix: {PREFIX}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## Step 2: Understand Data Format\n",
    "\n",
    "SageMaker Image Classification supports multiple data formats:\n",
    "\n",
    "### RecordIO Format (Recommended for MXNet)\n",
    "Binary format packing images and labels together.\n",
    "\n",
    "### Image Files + LST File\n",
    "```\n",
    "# train.lst format: index \\t label \\t path\n",
    "0\\t0\\ttrain/cat/image001.jpg\n",
    "1\\t0\\ttrain/cat/image002.jpg\n",
    "2\\t1\\ttrain/dog/image001.jpg\n",
    "3\\t1\\ttrain/dog/image002.jpg\n",
    "```\n",
    "\n",
    "### Augmented Manifest Format\n",
    "```json\n",
    "{\"source-ref\": \"s3://bucket/image.jpg\", \"class\": 0}\n",
    "```\n",
    "\n",
    "### Multi-label Classification\n",
    "```\n",
    "# For multi-label: label is comma-separated indices\n",
    "0\\t0,2\\ttrain/image001.jpg  # Classes 0 and 2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample_lst_file(num_samples=100, num_classes=5):\n",
    "    \"\"\"\n",
    "    Generate a sample LST file content.\n",
    "    \n",
    "    LST format: index \\t label \\t image_path\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    class_names = ['airplane', 'automobile', 'bird', 'cat', 'dog']\n",
    "    lines = []\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        label = np.random.randint(0, num_classes)\n",
    "        class_name = class_names[label]\n",
    "        image_path = f\"train/{class_name}/image_{i:04d}.jpg\"\n",
    "        lines.append(f\"{i}\\t{label}\\t{image_path}\")\n",
    "    \n",
    "    return lines, class_names\n",
    "\n",
    "lst_lines, class_names = generate_sample_lst_file()\n",
    "\n",
    "print(\"Sample LST file content:\")\n",
    "print(\"Format: index\\tlabel\\tpath\")\n",
    "print(\"-\" * 50)\n",
    "for line in lst_lines[:10]:\n",
    "    print(line)\n",
    "print(\"...\")\n",
    "\n",
    "print(f\"\\nClasses: {class_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## Step 3: Training Configuration\n",
    "\n",
    "### Key Hyperparameters\n",
    "\n",
    "| Parameter | Description | Default |\n",
    "|-----------|-------------|---------|\n",
    "| `num_classes` | Number of output classes | Required |\n",
    "| `num_training_samples` | Number of training images | Required |\n",
    "| `num_layers` | ResNet depth: 18, 34, 50, 101, 152, 200 | 152 |\n",
    "| `use_pretrained_model` | Use ImageNet pretrained weights | 1 |\n",
    "| `epochs` | Training epochs | 30 |\n",
    "| `learning_rate` | Initial learning rate | 0.1 |\n",
    "| `mini_batch_size` | Batch size | 32 |\n",
    "| `image_shape` | \"channels,height,width\" | 3,224,224 |\n",
    "| `augmentation_type` | crop, crop_color, crop_color_transform | crop_color_transform |\n",
    "| `top_k` | Report top-k accuracy | 5 |\n",
    "| `multi_label` | Enable multi-label classification | 0 |\n",
    "\n",
    "### Training Modes\n",
    "\n",
    "| Mode | Description | When to Use |\n",
    "|------|-------------|-------------|\n",
    "| Full Training | Train from scratch | Large datasets, unique domains |\n",
    "| Transfer Learning | Fine-tune pretrained model | Small datasets, similar to ImageNet |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Image Classification container image\n",
    "image_classification_image = retrieve(\n",
    "    framework='image-classification',\n",
    "    region=region,\n",
    "    version='1'\n",
    ")\n",
    "\n",
    "print(f\"Image Classification Image URI: {image_classification_image}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example estimator configuration (for reference)\n",
    "print(\"\"\"\n",
    "Image Classification Estimator Configuration:\n",
    "=============================================\n",
    "\n",
    "image_classification_estimator = Estimator(\n",
    "    image_uri=image_classification_image,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.p3.2xlarge',  # GPU required\n",
    "    output_path=f's3://{BUCKET_NAME}/{PREFIX}/output',\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    base_job_name='image-classification'\n",
    ")\n",
    "\n",
    "hyperparameters = {\n",
    "    \"num_classes\": 5,\n",
    "    \"num_training_samples\": 10000,\n",
    "    \"num_layers\": 50,              # ResNet-50\n",
    "    \"use_pretrained_model\": 1,     # Transfer learning\n",
    "    \"epochs\": 30,\n",
    "    \"learning_rate\": 0.001,        # Lower for fine-tuning\n",
    "    \"lr_scheduler_step\": \"10,20\",\n",
    "    \"lr_scheduler_factor\": 0.1,\n",
    "    \"mini_batch_size\": 32,\n",
    "    \"image_shape\": \"3,224,224\",\n",
    "    \"augmentation_type\": \"crop_color_transform\",\n",
    "    \"optimizer\": \"sgd\",\n",
    "    \"momentum\": 0.9,\n",
    "    \"weight_decay\": 0.0001,\n",
    "    \"top_k\": 5,\n",
    "    \"precision_dtype\": \"float32\",\n",
    "}\n",
    "\n",
    "Data channels:\n",
    "- train: Training images (RecordIO or image folder + lst)\n",
    "- validation: Validation images\n",
    "- train_lst: Training list file (if using images)\n",
    "- validation_lst: Validation list file\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## Step 4: Understanding Model Output\n",
    "\n",
    "The model outputs a probability distribution over classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_classification_output(probabilities, class_names, top_k=5):\n",
    "    \"\"\"\n",
    "    Parse classification output and return top-k predictions.\n",
    "    \n",
    "    Args:\n",
    "        probabilities: Array of class probabilities\n",
    "        class_names: List of class names\n",
    "        top_k: Number of top predictions to return\n",
    "    \"\"\"\n",
    "    # Sort by probability descending\n",
    "    top_indices = np.argsort(probabilities)[::-1][:top_k]\n",
    "    \n",
    "    results = []\n",
    "    for idx in top_indices:\n",
    "        results.append({\n",
    "            'class': class_names[idx],\n",
    "            'class_id': idx,\n",
    "            'probability': probabilities[idx]\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Simulate model output\n",
    "np.random.seed(42)\n",
    "sample_probs = np.random.dirichlet(np.ones(5))  # Random probability distribution\n",
    "\n",
    "predictions = parse_classification_output(sample_probs, class_names)\n",
    "\n",
    "print(\"Sample classification output:\")\n",
    "print(\"=\" * 40)\n",
    "for pred in predictions:\n",
    "    print(f\"  {pred['class']}: {pred['probability']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_predictions(probabilities, class_names, title=\"Predictions\"):\n",
    "    \"\"\"\n",
    "    Visualize classification probabilities as a bar chart.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    \n",
    "    colors = plt.cm.viridis(probabilities / max(probabilities))\n",
    "    bars = ax.barh(class_names, probabilities, color=colors)\n",
    "    \n",
    "    ax.set_xlabel('Probability')\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlim(0, 1)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar, prob in zip(bars, probabilities):\n",
    "        ax.text(bar.get_width() + 0.02, bar.get_y() + bar.get_height()/2,\n",
    "               f'{prob:.4f}', va='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_predictions(sample_probs, class_names, \"Sample Image Classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## Step 5: Evaluation Metrics\n",
    "\n",
    "### Single-label Classification\n",
    "- **Top-1 Accuracy**: Correct if top prediction matches label\n",
    "- **Top-5 Accuracy**: Correct if label is in top 5 predictions\n",
    "\n",
    "### Multi-label Classification\n",
    "- **Precision**: Fraction of predicted labels that are correct\n",
    "- **Recall**: Fraction of true labels that are predicted\n",
    "- **F1 Score**: Harmonic mean of precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_topk_accuracy(predictions_list, true_labels, k=5):\n",
    "    \"\"\"\n",
    "    Calculate top-k accuracy.\n",
    "    \n",
    "    Args:\n",
    "        predictions_list: List of probability arrays\n",
    "        true_labels: List of true class indices\n",
    "        k: Top-k parameter\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    for probs, true_label in zip(predictions_list, true_labels):\n",
    "        top_k_preds = np.argsort(probs)[::-1][:k]\n",
    "        if true_label in top_k_preds:\n",
    "            correct += 1\n",
    "    \n",
    "    return correct / len(predictions_list)\n",
    "\n",
    "# Simulate evaluation\n",
    "np.random.seed(42)\n",
    "num_test_samples = 100\n",
    "\n",
    "# Generate random predictions and labels\n",
    "test_predictions = [np.random.dirichlet(np.ones(5)) for _ in range(num_test_samples)]\n",
    "test_labels = np.random.randint(0, 5, num_test_samples)\n",
    "\n",
    "top1_acc = calculate_topk_accuracy(test_predictions, test_labels, k=1)\n",
    "top3_acc = calculate_topk_accuracy(test_predictions, test_labels, k=3)\n",
    "top5_acc = calculate_topk_accuracy(test_predictions, test_labels, k=5)\n",
    "\n",
    "print(\"Evaluation Metrics (random predictions):\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Top-1 Accuracy: {top1_acc:.4f}\")\n",
    "print(f\"Top-3 Accuracy: {top3_acc:.4f}\")\n",
    "print(f\"Top-5 Accuracy: {top5_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "## Step 6: Data Augmentation\n",
    "\n",
    "SageMaker Image Classification supports these augmentation types:\n",
    "\n",
    "| Type | Description |\n",
    "|------|-------------|\n",
    "| `crop` | Random cropping |\n",
    "| `crop_color` | Random crop + color jittering |\n",
    "| `crop_color_transform` | Crop + color + geometric transforms |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "Data Augmentation Options:\n",
    "==========================\n",
    "\n",
    "1. crop:\n",
    "   - Random crop from larger image\n",
    "   - Horizontal flip\n",
    "\n",
    "2. crop_color:\n",
    "   - All of 'crop' plus:\n",
    "   - Brightness adjustment\n",
    "   - Saturation adjustment\n",
    "   - Hue adjustment\n",
    "\n",
    "3. crop_color_transform:\n",
    "   - All of 'crop_color' plus:\n",
    "   - Rotation\n",
    "   - Shear\n",
    "   - Aspect ratio change\n",
    "\n",
    "Best Practices:\n",
    "- Use 'crop_color_transform' for small datasets\n",
    "- Use 'crop' for large datasets (faster training)\n",
    "- Match image_shape to your network (224x224 for ResNet)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "In this exercise, you learned:\n",
    "\n",
    "1. **Data Formats**:\n",
    "   - RecordIO (binary, efficient)\n",
    "   - Image folder + LST file\n",
    "   - Augmented manifest\n",
    "\n",
    "2. **Key Hyperparameters**:\n",
    "   - `num_layers`: ResNet depth (50 recommended)\n",
    "   - `use_pretrained_model`: Transfer learning\n",
    "   - `image_shape`: Input dimensions\n",
    "   - `augmentation_type`: Data augmentation\n",
    "\n",
    "3. **Training Modes**:\n",
    "   - Full training: Large datasets\n",
    "   - Transfer learning: Small datasets\n",
    "\n",
    "4. **Output Format**:\n",
    "   - Probability distribution over classes\n",
    "   - Top-k predictions\n",
    "\n",
    "5. **Evaluation Metrics**:\n",
    "   - Top-1, Top-5 accuracy\n",
    "   - Precision, Recall, F1 for multi-label\n",
    "\n",
    "### Instance Requirements\n",
    "\n",
    "| Task | Instance Types |\n",
    "|------|----------------|\n",
    "| Training | ml.p2.xlarge, ml.p3.2xlarge, ml.g4dn.xlarge |\n",
    "| Inference | ml.m5.large (CPU) or ml.c5.large |\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Prepare real image dataset\n",
    "- Use SageMaker Ground Truth for labeling\n",
    "- Try TensorFlow Image Classification for more models\n",
    "- Implement multi-label classification"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
