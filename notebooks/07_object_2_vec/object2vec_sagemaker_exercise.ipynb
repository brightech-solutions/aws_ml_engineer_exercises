{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# SageMaker Object2Vec Exercise\n",
    "\n",
    "This notebook demonstrates Amazon SageMaker's **Object2Vec** algorithm for learning embeddings of pairs of objects.\n",
    "\n",
    "## What You'll Learn\n",
    "1. How to prepare paired data for Object2Vec\n",
    "2. How to train embeddings for relationship learning\n",
    "3. How to use embeddings for similarity search and classification\n",
    "\n",
    "## What is Object2Vec?\n",
    "\n",
    "Object2Vec is a general-purpose neural embedding algorithm that learns low-dimensional dense embeddings of high-dimensional objects. It generalizes Word2Vec to arbitrary object pairs.\n",
    "\n",
    "**Key Features:**\n",
    "- Learns embeddings from paired objects (e.g., user-item, sentence-sentence)\n",
    "- Supports discrete tokens and sequences as inputs\n",
    "- Can handle asymmetric pairs (e.g., query-document)\n",
    "- Embeddings can be used for downstream tasks\n",
    "\n",
    "## Use Cases\n",
    "\n",
    "| Use Case | Pair Type | Example |\n",
    "|----------|-----------|----------|\n",
    "| Recommendation | (user, item) | Predict user ratings |\n",
    "| Sentence similarity | (sentence, sentence) | Semantic similarity |\n",
    "| Document classification | (document, label) | Multi-class classification |\n",
    "| Entity resolution | (entity1, entity2) | Match duplicate records |\n",
    "\n",
    "## Architecture\n",
    "\n",
    "```\n",
    "Input Pair: (obj1, obj2)\n",
    "       ↓         ↓\n",
    "   Encoder0   Encoder1\n",
    "       ↓         ↓\n",
    "   embed1     embed2\n",
    "       ↘       ↙\n",
    "       Comparator\n",
    "           ↓\n",
    "       Output (label/score)\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Step 1: Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.image_uris import retrieve\n",
    "from sagemaker.estimator import Estimator\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "from collections import defaultdict\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Configure AWS session from environment variables\n",
    "aws_profile = os.getenv('AWS_PROFILE')\n",
    "aws_region = os.getenv('AWS_REGION', 'us-west-2')\n",
    "sagemaker_role = os.getenv('SAGEMAKER_ROLE_ARN')\n",
    "\n",
    "if aws_profile:\n",
    "    boto3.setup_default_session(profile_name=aws_profile, region_name=aws_region)\n",
    "else:\n",
    "    boto3.setup_default_session(region_name=aws_region)\n",
    "\n",
    "# SageMaker session and role\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "if sagemaker_role:\n",
    "    role = sagemaker_role\n",
    "else:\n",
    "    role = get_execution_role()\n",
    "\n",
    "region = sagemaker_session.boto_region_name\n",
    "\n",
    "print(f\"AWS Profile: {aws_profile or 'default'}\")\n",
    "print(f\"SageMaker Role: {role}\")\n",
    "print(f\"Region: {region}\")\n",
    "print(f\"SageMaker SDK Version: {sagemaker.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "BUCKET_NAME = sagemaker_session.default_bucket()\n",
    "PREFIX = \"object2vec\"\n",
    "\n",
    "# Dataset parameters\n",
    "NUM_USERS = 500\n",
    "NUM_ITEMS = 200\n",
    "NUM_INTERACTIONS = 10000\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "print(f\"S3 Bucket: {BUCKET_NAME}\")\n",
    "print(f\"S3 Prefix: {PREFIX}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## Step 2: Generate Synthetic Data\n",
    "\n",
    "We'll create a synthetic user-item interaction dataset for a recommendation system scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_user_item_data(num_users=500, num_items=200, num_interactions=10000, seed=42):\n",
    "    \"\"\"\n",
    "    Generate synthetic user-item interaction data.\n",
    "    \n",
    "    Creates users with preferences for certain item categories,\n",
    "    simulating realistic interaction patterns.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Define item categories (items belong to categories)\n",
    "    num_categories = 5\n",
    "    item_categories = np.random.randint(0, num_categories, num_items)\n",
    "    \n",
    "    # Define user preferences (users prefer certain categories)\n",
    "    user_preferences = np.random.dirichlet(np.ones(num_categories), num_users)\n",
    "    \n",
    "    interactions = []\n",
    "    \n",
    "    for _ in range(num_interactions):\n",
    "        # Sample a user\n",
    "        user_id = np.random.randint(0, num_users)\n",
    "        \n",
    "        # Sample a category based on user preference\n",
    "        preferred_category = np.random.choice(num_categories, p=user_preferences[user_id])\n",
    "        \n",
    "        # Get items in that category\n",
    "        category_items = np.where(item_categories == preferred_category)[0]\n",
    "        \n",
    "        if len(category_items) > 0:\n",
    "            # Sample an item from preferred category\n",
    "            item_id = np.random.choice(category_items)\n",
    "            # Positive interaction (user likes item from preferred category)\n",
    "            label = 1\n",
    "        else:\n",
    "            # Random item (less likely to be liked)\n",
    "            item_id = np.random.randint(0, num_items)\n",
    "            label = 0\n",
    "        \n",
    "        # Add some noise\n",
    "        if np.random.random() < 0.1:\n",
    "            label = 1 - label  # Flip label with 10% probability\n",
    "        \n",
    "        interactions.append({\n",
    "            'user_id': user_id,\n",
    "            'item_id': item_id,\n",
    "            'label': label\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(interactions), item_categories, user_preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data\n",
    "print(\"Generating user-item interaction data...\")\n",
    "df, item_categories, user_preferences = generate_user_item_data(\n",
    "    NUM_USERS, NUM_ITEMS, NUM_INTERACTIONS, RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(f\"\\nDataset shape: {df.shape}\")\n",
    "print(f\"\\nLabel distribution:\")\n",
    "print(df['label'].value_counts())\n",
    "\n",
    "print(f\"\\nSample interactions:\")\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train, validation, and test\n",
    "np.random.seed(RANDOM_STATE)\n",
    "indices = np.random.permutation(len(df))\n",
    "\n",
    "train_size = int(0.8 * len(df))\n",
    "val_size = int(0.1 * len(df))\n",
    "\n",
    "train_idx = indices[:train_size]\n",
    "val_idx = indices[train_size:train_size + val_size]\n",
    "test_idx = indices[train_size + val_size:]\n",
    "\n",
    "train_df = df.iloc[train_idx]\n",
    "val_df = df.iloc[val_idx]\n",
    "test_df = df.iloc[test_idx]\n",
    "\n",
    "print(f\"Training samples: {len(train_df)}\")\n",
    "print(f\"Validation samples: {len(val_df)}\")\n",
    "print(f\"Test samples: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## Step 3: Prepare Data for Object2Vec\n",
    "\n",
    "Object2Vec expects data in JSON Lines format with specific structure:\n",
    "\n",
    "```json\n",
    "{\"in0\": [token_ids], \"in1\": [token_ids], \"label\": label_value}\n",
    "```\n",
    "\n",
    "**Input Types:**\n",
    "- **Discrete token**: `[single_id]` - e.g., `[42]` for user_id 42\n",
    "- **Sequence**: `[id1, id2, id3, ...]` - e.g., word IDs in a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_object2vec_format(df):\n",
    "    \"\"\"\n",
    "    Convert DataFrame to Object2Vec JSON Lines format.\n",
    "    \n",
    "    Format: {\"in0\": [user_id], \"in1\": [item_id], \"label\": label}\n",
    "    \"\"\"\n",
    "    records = []\n",
    "    for _, row in df.iterrows():\n",
    "        record = {\n",
    "            \"in0\": [int(row['user_id'])],  # User as discrete token\n",
    "            \"in1\": [int(row['item_id'])],  # Item as discrete token\n",
    "            \"label\": int(row['label'])\n",
    "        }\n",
    "        records.append(json.dumps(record))\n",
    "    return records\n",
    "\n",
    "# Convert datasets\n",
    "train_records = convert_to_object2vec_format(train_df)\n",
    "val_records = convert_to_object2vec_format(val_df)\n",
    "test_records = convert_to_object2vec_format(test_df)\n",
    "\n",
    "print(\"Sample training records:\")\n",
    "for record in train_records[:5]:\n",
    "    print(f\"  {record}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to local files\n",
    "os.makedirs('data/object2vec', exist_ok=True)\n",
    "\n",
    "with open('data/object2vec/train.jsonl', 'w') as f:\n",
    "    f.write('\\n'.join(train_records))\n",
    "\n",
    "with open('data/object2vec/validation.jsonl', 'w') as f:\n",
    "    f.write('\\n'.join(val_records))\n",
    "\n",
    "with open('data/object2vec/test.jsonl', 'w') as f:\n",
    "    f.write('\\n'.join(test_records))\n",
    "\n",
    "print(\"Data files created:\")\n",
    "for f in ['train.jsonl', 'validation.jsonl', 'test.jsonl']:\n",
    "    size = os.path.getsize(f'data/object2vec/{f}') / 1024\n",
    "    print(f\"  data/object2vec/{f} ({size:.1f} KB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload to S3\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "for split in ['train', 'validation', 'test']:\n",
    "    s3_key = f\"{PREFIX}/{split}/{split}.jsonl\"\n",
    "    s3_client.upload_file(f'data/object2vec/{split}.jsonl', BUCKET_NAME, s3_key)\n",
    "    print(f\"Uploaded: s3://{BUCKET_NAME}/{s3_key}\")\n",
    "\n",
    "train_uri = f\"s3://{BUCKET_NAME}/{PREFIX}/train\"\n",
    "val_uri = f\"s3://{BUCKET_NAME}/{PREFIX}/validation\"\n",
    "test_uri = f\"s3://{BUCKET_NAME}/{PREFIX}/test\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## Step 4: Train Object2Vec Model\n",
    "\n",
    "### Key Hyperparameters\n",
    "\n",
    "| Parameter | Description | Default |\n",
    "|-----------|-------------|---------|\n",
    "| `enc0_max_seq_len` | Max sequence length for encoder 0 | 1 |\n",
    "| `enc1_max_seq_len` | Max sequence length for encoder 1 | 1 |\n",
    "| `enc0_vocab_size` | Vocabulary size for encoder 0 | Required |\n",
    "| `enc1_vocab_size` | Vocabulary size for encoder 1 | Required |\n",
    "| `enc_dim` | Encoder embedding dimension | 4096 |\n",
    "| `output_layer` | Comparator: `softmax` (classification) or `mean_squared_error` (regression) | softmax |\n",
    "| `epochs` | Training epochs | 30 |\n",
    "| `learning_rate` | Learning rate | 0.0004 |\n",
    "| `mini_batch_size` | Batch size | 32 |\n",
    "| `mlp_layers` | Hidden layer sizes in comparator | 512 |\n",
    "| `mlp_activation` | Activation function | relu |\n",
    "| `token_embedding_dim` | Token embedding dimension | 300 |\n",
    "| `comparator_list` | Comparison operations | hadamard, concat |\n",
    "\n",
    "### Encoder Types\n",
    "\n",
    "| Encoder | Use Case |\n",
    "|---------|----------|\n",
    "| `pooled_embedding` | Simple pooling of token embeddings |\n",
    "| `hcnn` | Hierarchical CNN for sequences |\n",
    "| `bilstm` | Bidirectional LSTM for sequences |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Object2Vec container image\n",
    "object2vec_image = retrieve(\n",
    "    framework='object2vec',\n",
    "    region=region,\n",
    "    version='1'\n",
    ")\n",
    "\n",
    "print(f\"Object2Vec Image URI: {object2vec_image}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Object2Vec estimator\n",
    "object2vec_estimator = Estimator(\n",
    "    image_uri=object2vec_image,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.xlarge',  # CPU instance for small datasets\n",
    "    output_path=f's3://{BUCKET_NAME}/{PREFIX}/output',\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    base_job_name='object2vec'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyperparameters\n",
    "hyperparameters = {\n",
    "    # Input configuration\n",
    "    \"enc0_max_seq_len\": 1,              # Single token (user_id)\n",
    "    \"enc1_max_seq_len\": 1,              # Single token (item_id)\n",
    "    \"enc0_vocab_size\": NUM_USERS,       # Number of unique users\n",
    "    \"enc1_vocab_size\": NUM_ITEMS,       # Number of unique items\n",
    "    \n",
    "    # Encoder configuration\n",
    "    \"enc0_network\": \"pooled_embedding\", # Simple embedding for discrete tokens\n",
    "    \"enc1_network\": \"pooled_embedding\",\n",
    "    \"enc0_token_embedding_dim\": 64,\n",
    "    \"enc1_token_embedding_dim\": 64,\n",
    "    \n",
    "    # Output configuration\n",
    "    \"output_layer\": \"softmax\",          # Binary classification\n",
    "    \"num_classes\": 2,\n",
    "    \n",
    "    # Comparator configuration\n",
    "    \"comparator_list\": \"hadamard,concat,abs_diff\",\n",
    "    \"mlp_layers\": 128,\n",
    "    \"mlp_activation\": \"relu\",\n",
    "    \"mlp_dim\": 256,\n",
    "    \n",
    "    # Training configuration\n",
    "    \"epochs\": 20,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"mini_batch_size\": 64,\n",
    "    \"early_stopping_patience\": 3,\n",
    "    \"early_stopping_tolerance\": 0.001,\n",
    "}\n",
    "\n",
    "object2vec_estimator.set_hyperparameters(**hyperparameters)\n",
    "\n",
    "print(\"Object2Vec hyperparameters:\")\n",
    "for k, v in hyperparameters.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "print(\"Starting Object2Vec training job...\")\n",
    "print(\"This will take approximately 5-10 minutes.\\n\")\n",
    "\n",
    "object2vec_estimator.fit(\n",
    "    {\n",
    "        'train': train_uri,\n",
    "        'validation': val_uri,\n",
    "        'test': test_uri\n",
    "    },\n",
    "    wait=True,\n",
    "    logs=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training job info\n",
    "job_name = object2vec_estimator.latest_training_job.name\n",
    "print(f\"Training job completed: {job_name}\")\n",
    "print(f\"Model artifacts: {object2vec_estimator.model_data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "## Step 5: Deploy and Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy the model\n",
    "print(\"Deploying Object2Vec model...\")\n",
    "print(\"This will take approximately 5-7 minutes.\\n\")\n",
    "\n",
    "predictor = object2vec_estimator.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m5.large',\n",
    "    endpoint_name=f'object2vec-{datetime.now().strftime(\"%Y%m%d%H%M\")}'\n",
    ")\n",
    "\n",
    "print(f\"\\nEndpoint deployed: {predictor.endpoint_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "# Configure predictor\n",
    "predictor.serializer = JSONSerializer()\n",
    "predictor.deserializer = JSONDeserializer()\n",
    "\n",
    "def predict_interaction(user_ids, item_ids):\n",
    "    \"\"\"\n",
    "    Predict whether users will like items.\n",
    "    \n",
    "    Args:\n",
    "        user_ids: List of user IDs\n",
    "        item_ids: List of item IDs\n",
    "    \n",
    "    Returns:\n",
    "        Predictions with scores\n",
    "    \"\"\"\n",
    "    instances = []\n",
    "    for user_id, item_id in zip(user_ids, item_ids):\n",
    "        instances.append({\n",
    "            \"in0\": [int(user_id)],\n",
    "            \"in1\": [int(item_id)]\n",
    "        })\n",
    "    \n",
    "    payload = {\"instances\": instances}\n",
    "    response = predictor.predict(payload)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test predictions\n",
    "print(\"Testing predictions on sample user-item pairs:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Get some test samples\n",
    "test_samples = test_df.head(10)\n",
    "\n",
    "user_ids = test_samples['user_id'].tolist()\n",
    "item_ids = test_samples['item_id'].tolist()\n",
    "true_labels = test_samples['label'].tolist()\n",
    "\n",
    "predictions = predict_interaction(user_ids, item_ids)\n",
    "\n",
    "print(f\"{'User':<8} {'Item':<8} {'True':<8} {'Pred':<8} {'Score':<10}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for i, pred in enumerate(predictions['predictions']):\n",
    "    scores = pred['scores']\n",
    "    pred_label = 1 if scores[1] > scores[0] else 0\n",
    "    confidence = max(scores)\n",
    "    \n",
    "    status = \"correct\" if pred_label == true_labels[i] else \"WRONG\"\n",
    "    print(f\"{user_ids[i]:<8} {item_ids[i]:<8} {true_labels[i]:<8} {pred_label:<8} {confidence:.4f} {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "## Step 6: Extract Embeddings\n",
    "\n",
    "Object2Vec can also return embeddings for individual objects, which is useful for similarity search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: To get embeddings, you need to deploy with a different inference mode\n",
    "# or use batch transform. For demonstration, we'll show the concept.\n",
    "\n",
    "print(\"Embedding Extraction Options:\")\n",
    "print(\"=\"*60)\n",
    "print(\"\"\"\n",
    "To extract embeddings instead of predictions, you can:\n",
    "\n",
    "1. Set INFERENCE_PREFERRED_MODE environment variable:\n",
    "   - 'embedding' - Returns embeddings instead of predictions\n",
    "   - 'classification' - Returns classification predictions (default)\n",
    "\n",
    "2. Provide only one input (in0 OR in1):\n",
    "   - If only in0 is provided, returns enc0 embedding\n",
    "   - If only in1 is provided, returns enc1 embedding\n",
    "\n",
    "Example embedding request:\n",
    "{\"instances\": [{\"in0\": [user_id]}]}  # Get user embedding\n",
    "{\"instances\": [{\"in1\": [item_id]}]}  # Get item embedding\n",
    "\n",
    "Embeddings can be used for:\n",
    "- Finding similar users/items via cosine similarity\n",
    "- Visualizing user/item clusters with t-SNE/UMAP\n",
    "- Downstream ML tasks as features\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-24",
   "metadata": {},
   "source": [
    "## Step 7: Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Evaluate on full test set\n",
    "print(\"Evaluating on test set...\")\n",
    "\n",
    "all_predictions = []\n",
    "all_scores = []\n",
    "batch_size = 100\n",
    "\n",
    "test_users = test_df['user_id'].tolist()\n",
    "test_items = test_df['item_id'].tolist()\n",
    "test_labels = test_df['label'].tolist()\n",
    "\n",
    "for i in range(0, len(test_df), batch_size):\n",
    "    batch_users = test_users[i:i+batch_size]\n",
    "    batch_items = test_items[i:i+batch_size]\n",
    "    \n",
    "    preds = predict_interaction(batch_users, batch_items)\n",
    "    \n",
    "    for pred in preds['predictions']:\n",
    "        scores = pred['scores']\n",
    "        pred_label = 1 if scores[1] > scores[0] else 0\n",
    "        all_predictions.append(pred_label)\n",
    "        all_scores.append(scores[1])  # Probability of class 1\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(test_labels, all_predictions)\n",
    "precision = precision_score(test_labels, all_predictions)\n",
    "recall = recall_score(test_labels, all_predictions)\n",
    "f1 = f1_score(test_labels, all_predictions)\n",
    "auc = roc_auc_score(test_labels, all_scores)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL EVALUATION RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"F1 Score:  {f1:.4f}\")\n",
    "print(f\"AUC-ROC:   {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-26",
   "metadata": {},
   "source": [
    "## Step 8: Clean Up Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the endpoint\n",
    "print(f\"Deleting endpoint: {predictor.endpoint_name}\")\n",
    "predictor.delete_endpoint()\n",
    "print(\"Endpoint deleted successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally clean up S3 data\n",
    "# Uncomment to delete:\n",
    "\n",
    "# s3 = boto3.resource('s3')\n",
    "# bucket = s3.Bucket(BUCKET_NAME)\n",
    "# bucket.objects.filter(Prefix=PREFIX).delete()\n",
    "# print(f\"Deleted all objects under s3://{BUCKET_NAME}/{PREFIX}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-29",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "In this exercise, you learned:\n",
    "\n",
    "1. **Data Format**: JSON Lines with `{\"in0\": [...], \"in1\": [...], \"label\": ...}`\n",
    "\n",
    "2. **Input Types**:\n",
    "   - Discrete tokens: `[single_id]`\n",
    "   - Sequences: `[id1, id2, ...]`\n",
    "\n",
    "3. **Encoder Options**:\n",
    "   - `pooled_embedding`: For discrete tokens\n",
    "   - `hcnn`: For sequences (CNN-based)\n",
    "   - `bilstm`: For sequences (RNN-based)\n",
    "\n",
    "4. **Output Modes**:\n",
    "   - Classification: `output_layer=softmax`\n",
    "   - Regression: `output_layer=mean_squared_error`\n",
    "   - Embeddings: Single input returns encoder embedding\n",
    "\n",
    "5. **Comparator Operations**: `hadamard`, `concat`, `abs_diff`\n",
    "\n",
    "### Use Cases Recap\n",
    "\n",
    "| Application | in0 | in1 | Label |\n",
    "|-------------|-----|-----|-------|\n",
    "| Recommendation | User ID | Item ID | Rating/Click |\n",
    "| Sentence Similarity | Sentence 1 tokens | Sentence 2 tokens | Similarity score |\n",
    "| Document Classification | Document tokens | Category ID | Match |\n",
    "| Entity Resolution | Entity 1 | Entity 2 | Same/Different |\n",
    "\n",
    "### Instance Recommendations\n",
    "\n",
    "| Task | Data Size | Instance |\n",
    "|------|-----------|----------|\n",
    "| Training (small) | < 1M pairs | ml.m5.xlarge |\n",
    "| Training (large) | > 1M pairs | ml.p2.xlarge or ml.p3.2xlarge |\n",
    "| Inference | Any | ml.m5.large or ml.p3.2xlarge |\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Try sequence inputs (e.g., sentence pairs for similarity)\n",
    "- Use pre-trained embeddings via auxiliary channel\n",
    "- Extract embeddings for visualization and similarity search\n",
    "- Combine with downstream classifiers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
