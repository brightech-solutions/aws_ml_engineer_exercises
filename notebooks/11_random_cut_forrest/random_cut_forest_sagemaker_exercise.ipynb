{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# SageMaker Random Cut Forest Exercise\n",
    "\n",
    "This notebook demonstrates Amazon SageMaker's **Random Cut Forest (RCF)** algorithm for anomaly detection.\n",
    "\n",
    "## What You'll Learn\n",
    "1. How to prepare data for anomaly detection\n",
    "2. How to configure and understand RCF hyperparameters\n",
    "3. How to train an RCF model\n",
    "4. How to interpret anomaly scores and evaluate detection performance\n",
    "\n",
    "## What is Random Cut Forest?\n",
    "\n",
    "Random Cut Forest is an **unsupervised** algorithm for detecting anomalous data points. It assigns an anomaly score to each data point - higher scores indicate more anomalous observations.\n",
    "\n",
    "**Key Concept:**\n",
    "- RCF builds a forest of random trees by recursively partitioning data\n",
    "- Anomalies are points that require fewer cuts to isolate\n",
    "- Works with arbitrary-dimensional input\n",
    "- Based on the research paper \"Robust Random Cut Forest Based Anomaly Detection On Streams\" (Guha et al.)\n",
    "\n",
    "## Use Cases\n",
    "\n",
    "| Domain | Application |\n",
    "|--------|-------------|\n",
    "| Time Series | Spike detection, unusual patterns |\n",
    "| Cybersecurity | Intrusion detection, fraud |\n",
    "| IoT | Sensor malfunction, equipment failure |\n",
    "| Finance | Transaction anomalies, market events |\n",
    "| Operations | Server issues, traffic anomalies |\n",
    "\n",
    "---\n",
    "\n",
    "## ⚠️ Training Cost Information\n",
    "\n",
    "<div style=\"background-color: #000000ff; border: 1px solid #28a745; border-radius: 5px; padding: 15px; margin: 10px 0;\">\n",
    "\n",
    "### RCF Uses CPU Instances (Cost-Effective!)\n",
    "\n",
    "Random Cut Forest is a **CPU-only** algorithm and does NOT require GPU instances.\n",
    "\n",
    "| Instance Type | vCPU | Memory | On-Demand Price* |\n",
    "|---------------|------|--------|------------------|\n",
    "| ml.m5.large | 2 | 8 GB | ~$0.13/hour |\n",
    "| ml.m5.xlarge | 4 | 16 GB | ~$0.27/hour |\n",
    "| ml.c5.xlarge | 4 | 8 GB | ~$0.24/hour |\n",
    "| ml.c5.2xlarge | 8 | 16 GB | ~$0.48/hour |\n",
    "\n",
    "*Prices are approximate for us-west-2. Check [AWS SageMaker Pricing](https://aws.amazon.com/sagemaker/pricing/) for current rates.\n",
    "\n",
    "### Cost Estimation\n",
    "- **Training**: Typically 3-5 minutes for small-medium datasets (~$0.01-0.03)\n",
    "- **Inference endpoint**: ~$0.13/hour for ml.m5.large (delete when not in use!)\n",
    "- RCF is one of the most cost-effective SageMaker algorithms\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Step 1: Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.image_uris import retrieve\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "from dotenv import load_dotenv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Configure AWS session from environment variables\n",
    "aws_profile = os.getenv('AWS_PROFILE')\n",
    "aws_region = os.getenv('AWS_REGION', 'us-west-2')\n",
    "sagemaker_role = os.getenv('SAGEMAKER_ROLE_ARN')\n",
    "\n",
    "if aws_profile:\n",
    "    boto3.setup_default_session(profile_name=aws_profile, region_name=aws_region)\n",
    "else:\n",
    "    boto3.setup_default_session(region_name=aws_region)\n",
    "\n",
    "# SageMaker session and role\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "if sagemaker_role:\n",
    "    role = sagemaker_role\n",
    "else:\n",
    "    role = get_execution_role()\n",
    "\n",
    "region = sagemaker_session.boto_region_name\n",
    "\n",
    "print(f\"AWS Profile: {aws_profile or 'default'}\")\n",
    "print(f\"SageMaker Role: {role}\")\n",
    "print(f\"Region: {region}\")\n",
    "print(f\"SageMaker SDK Version: {sagemaker.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "BUCKET_NAME = sagemaker_session.default_bucket()\n",
    "PREFIX = \"random-cut-forest\"\n",
    "\n",
    "# Dataset parameters\n",
    "NUM_SAMPLES = 5000\n",
    "ANOMALY_RATE = 0.02  # 2% anomalies\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "print(f\"S3 Bucket: {BUCKET_NAME}\")\n",
    "print(f\"S3 Prefix: {PREFIX}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## Step 2: Generate Synthetic Data with Anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_time_series_with_anomalies(num_samples=5000, anomaly_rate=0.02, seed=42):\n",
    "    \"\"\"\n",
    "    Generate synthetic time series data with injected anomalies.\n",
    "    \n",
    "    Simulates server metrics: CPU usage, memory, request count.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Time index\n",
    "    timestamps = pd.date_range(\n",
    "        start='2024-01-01', \n",
    "        periods=num_samples, \n",
    "        freq='5min'\n",
    "    )\n",
    "    \n",
    "    # Normal patterns\n",
    "    # CPU: base load + daily pattern + noise\n",
    "    hours = np.array([t.hour for t in timestamps])\n",
    "    daily_pattern = 20 * np.sin(2 * np.pi * hours / 24 - np.pi/2) + 50\n",
    "    cpu_usage = daily_pattern + np.random.normal(0, 5, num_samples)\n",
    "    cpu_usage = np.clip(cpu_usage, 0, 100)\n",
    "    \n",
    "    # Memory: slow growth + noise\n",
    "    memory_base = 40 + 0.002 * np.arange(num_samples)\n",
    "    memory_usage = memory_base + np.random.normal(0, 3, num_samples)\n",
    "    memory_usage = np.clip(memory_usage, 0, 100)\n",
    "    \n",
    "    # Request count: follows CPU pattern roughly\n",
    "    request_count = (daily_pattern - 30) * 100 + np.random.normal(0, 200, num_samples)\n",
    "    request_count = np.clip(request_count, 0, None)\n",
    "    \n",
    "    # Create dataframe\n",
    "    df = pd.DataFrame({\n",
    "        'timestamp': timestamps,\n",
    "        'cpu_usage': cpu_usage,\n",
    "        'memory_usage': memory_usage,\n",
    "        'request_count': request_count\n",
    "    })\n",
    "    \n",
    "    # Inject anomalies\n",
    "    num_anomalies = int(num_samples * anomaly_rate)\n",
    "    anomaly_indices = np.random.choice(num_samples, num_anomalies, replace=False)\n",
    "    \n",
    "    # Mark anomalies (for evaluation only - RCF doesn't use labels)\n",
    "    df['is_anomaly'] = False\n",
    "    df.loc[anomaly_indices, 'is_anomaly'] = True\n",
    "    \n",
    "    # Types of anomalies:\n",
    "    for idx in anomaly_indices:\n",
    "        anomaly_type = np.random.choice(['spike', 'drop', 'outlier'])\n",
    "        \n",
    "        if anomaly_type == 'spike':\n",
    "            # Sudden spike in CPU or memory\n",
    "            df.loc[idx, 'cpu_usage'] = min(100, df.loc[idx, 'cpu_usage'] + np.random.uniform(30, 50))\n",
    "            df.loc[idx, 'memory_usage'] = min(100, df.loc[idx, 'memory_usage'] + np.random.uniform(20, 40))\n",
    "        elif anomaly_type == 'drop':\n",
    "            # Sudden drop in requests\n",
    "            df.loc[idx, 'request_count'] = max(0, df.loc[idx, 'request_count'] * np.random.uniform(0.1, 0.3))\n",
    "        else:\n",
    "            # Multi-dimensional outlier\n",
    "            df.loc[idx, 'cpu_usage'] = np.random.uniform(85, 100)\n",
    "            df.loc[idx, 'memory_usage'] = np.random.uniform(80, 100)\n",
    "            df.loc[idx, 'request_count'] = np.random.uniform(0, 500)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Generate data\n",
    "df = generate_time_series_with_anomalies(NUM_SAMPLES, ANOMALY_RATE, RANDOM_STATE)\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "print(f\"\\nAnomaly count: {df['is_anomaly'].sum()} ({100*df['is_anomaly'].mean():.1f}%)\")\n",
    "print(f\"\\nSample data:\")\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the data with anomalies highlighted\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 10), sharex=True)\n",
    "\n",
    "# Get anomaly indices for plotting\n",
    "anomaly_mask = df['is_anomaly']\n",
    "\n",
    "# CPU Usage\n",
    "axes[0].plot(df.index, df['cpu_usage'], 'b-', alpha=0.7, label='CPU Usage')\n",
    "axes[0].scatter(df.index[anomaly_mask], df.loc[anomaly_mask, 'cpu_usage'], \n",
    "                c='red', s=50, label='Anomaly', zorder=5)\n",
    "axes[0].set_ylabel('CPU Usage (%)')\n",
    "axes[0].legend()\n",
    "axes[0].set_title('Server Metrics with Injected Anomalies')\n",
    "\n",
    "# Memory Usage\n",
    "axes[1].plot(df.index, df['memory_usage'], 'g-', alpha=0.7, label='Memory Usage')\n",
    "axes[1].scatter(df.index[anomaly_mask], df.loc[anomaly_mask, 'memory_usage'], \n",
    "                c='red', s=50, label='Anomaly', zorder=5)\n",
    "axes[1].set_ylabel('Memory Usage (%)')\n",
    "axes[1].legend()\n",
    "\n",
    "# Request Count\n",
    "axes[2].plot(df.index, df['request_count'], 'm-', alpha=0.7, label='Request Count')\n",
    "axes[2].scatter(df.index[anomaly_mask], df.loc[anomaly_mask, 'request_count'], \n",
    "                c='red', s=50, label='Anomaly', zorder=5)\n",
    "axes[2].set_ylabel('Requests')\n",
    "axes[2].set_xlabel('Sample Index')\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## Step 3: Prepare Data for RCF\n",
    "\n",
    "RCF accepts:\n",
    "- **CSV format**: text/csv\n",
    "- **RecordIO-protobuf**: application/x-recordio-protobuf\n",
    "\n",
    "For CSV, no header row, just numeric features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features (exclude timestamp and is_anomaly label)\n",
    "feature_columns = ['cpu_usage', 'memory_usage', 'request_count']\n",
    "train_data = df[feature_columns].values\n",
    "\n",
    "print(f\"Training data shape: {train_data.shape}\")\n",
    "print(f\"Features: {feature_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV (no header)\n",
    "os.makedirs('data/rcf', exist_ok=True)\n",
    "\n",
    "np.savetxt('data/rcf/train.csv', train_data, delimiter=',')\n",
    "\n",
    "print(f\"Saved: data/rcf/train.csv ({os.path.getsize('data/rcf/train.csv') / 1024:.1f} KB)\")\n",
    "\n",
    "# Preview\n",
    "print(\"\\nFile preview (first 5 lines):\")\n",
    "with open('data/rcf/train.csv', 'r') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i >= 5:\n",
    "            break\n",
    "        print(f\"  {line.strip()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload to S3\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "train_s3_key = f\"{PREFIX}/train/train.csv\"\n",
    "s3_client.upload_file('data/rcf/train.csv', BUCKET_NAME, train_s3_key)\n",
    "\n",
    "train_uri = f\"s3://{BUCKET_NAME}/{PREFIX}/train\"\n",
    "print(f\"Data uploaded to: {train_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## Step 4: Train RCF Model\n",
    "\n",
    "### Understanding RCF Hyperparameters\n",
    "\n",
    "| Parameter | Description | Default | Recommendation |\n",
    "|-----------|-------------|---------|----------------|\n",
    "| `num_trees` | Number of trees in forest | 50 | 50-100 for stability |\n",
    "| `num_samples_per_tree` | Samples used to build each tree | 256 | ~1/anomaly_rate |\n",
    "| `feature_dim` | Input feature dimension | Required | Must match data |\n",
    "| `eval_metrics` | Metrics to compute | None | `accuracy`, `f1` |\n",
    "\n",
    "### Key Hyperparameter Details\n",
    "\n",
    "**num_trees**\n",
    "- More trees = more stable anomaly scores\n",
    "- Diminishing returns beyond 100 trees\n",
    "- Recommended: 50-100 for most use cases\n",
    "- Higher values increase training time linearly\n",
    "\n",
    "**num_samples_per_tree**\n",
    "- Critical parameter for anomaly detection sensitivity\n",
    "- **Rule of thumb**: `1/num_samples_per_tree ≈ expected_anomaly_rate`\n",
    "- Example: 2% anomaly rate → `num_samples_per_tree=50` (1/50 = 2%)\n",
    "- Default of 256 expects ~0.4% anomaly rate\n",
    "- Lower values = more sensitive to small anomalies\n",
    "- Higher values = more robust, less false positives\n",
    "\n",
    "**feature_dim**\n",
    "- Must equal the number of input features\n",
    "- RCF handles high-dimensional data well (tested up to 50+ dimensions)\n",
    "\n",
    "### Evaluation Metrics Explained\n",
    "\n",
    "| Metric | Description | Usage |\n",
    "|--------|-------------|-------|\n",
    "| `accuracy` | Classification accuracy at threshold | Requires labeled test data |\n",
    "| `f1` | F1 score at threshold | Balance precision/recall |\n",
    "| `precision` | True positives / Predicted positives | Minimize false alarms |\n",
    "| `recall` | True positives / Actual positives | Catch all anomalies |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get RCF container image\n",
    "rcf_image = retrieve(\n",
    "    framework='randomcutforest',\n",
    "    region=region,\n",
    "    version='1'\n",
    ")\n",
    "\n",
    "print(f\"RCF Image URI: {rcf_image}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create RCF estimator\n",
    "rcf_estimator = Estimator(\n",
    "    image_uri=rcf_image,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.large',  # CPU instance\n",
    "    output_path=f's3://{BUCKET_NAME}/{PREFIX}/output',\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    base_job_name='random-cut-forest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyperparameters\n",
    "hyperparameters = {\n",
    "    \"num_trees\": 100,\n",
    "    \"num_samples_per_tree\": 256,  # ~0.4% expected anomaly rate (1/256)\n",
    "    \"feature_dim\": len(feature_columns),\n",
    "}\n",
    "\n",
    "rcf_estimator.set_hyperparameters(**hyperparameters)\n",
    "\n",
    "print(\"RCF hyperparameters:\")\n",
    "for k, v in hyperparameters.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "print(\"Starting RCF training job...\")\n",
    "print(\"This will take approximately 3-5 minutes.\\n\")\n",
    "\n",
    "rcf_estimator.fit(\n",
    "    {'train': train_uri},\n",
    "    wait=True,\n",
    "    logs=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training job info\n",
    "job_name = rcf_estimator.latest_training_job.name\n",
    "print(f\"Training job completed: {job_name}\")\n",
    "print(f\"Model artifacts: {rcf_estimator.model_data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "## Step 5: Deploy and Score Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy the model\n",
    "print(\"Deploying RCF model...\")\n",
    "print(\"This will take approximately 5-7 minutes.\\n\")\n",
    "\n",
    "rcf_predictor = rcf_estimator.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m5.large',\n",
    "    endpoint_name=f'rcf-{datetime.now().strftime(\"%Y%m%d%H%M\")}'\n",
    ")\n",
    "\n",
    "print(f\"\\nEndpoint deployed: {rcf_predictor.endpoint_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure predictor\n",
    "rcf_predictor.serializer = CSVSerializer()\n",
    "rcf_predictor.deserializer = JSONDeserializer()\n",
    "\n",
    "def get_anomaly_scores(data, predictor, batch_size=500):\n",
    "    \"\"\"\n",
    "    Get anomaly scores for all data points.\n",
    "    \"\"\"\n",
    "    all_scores = []\n",
    "    \n",
    "    for i in range(0, len(data), batch_size):\n",
    "        batch = data[i:i+batch_size]\n",
    "        response = predictor.predict(batch)\n",
    "        \n",
    "        for result in response['scores']:\n",
    "            all_scores.append(result['score'])\n",
    "    \n",
    "    return np.array(all_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get anomaly scores for all data\n",
    "print(\"Computing anomaly scores...\")\n",
    "scores = get_anomaly_scores(train_data, rcf_predictor)\n",
    "\n",
    "# Add scores to dataframe\n",
    "df['anomaly_score'] = scores\n",
    "\n",
    "print(f\"\\nScore statistics:\")\n",
    "print(f\"  Min:    {scores.min():.4f}\")\n",
    "print(f\"  Max:    {scores.max():.4f}\")\n",
    "print(f\"  Mean:   {scores.mean():.4f}\")\n",
    "print(f\"  Median: {np.median(scores):.4f}\")\n",
    "print(f\"  Std:    {scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize anomaly scores\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 8))\n",
    "\n",
    "# Score distribution\n",
    "axes[0].hist(scores[~df['is_anomaly']], bins=50, alpha=0.7, label='Normal', color='blue')\n",
    "axes[0].hist(scores[df['is_anomaly']], bins=50, alpha=0.7, label='True Anomaly', color='red')\n",
    "axes[0].set_xlabel('Anomaly Score')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Distribution of Anomaly Scores')\n",
    "axes[0].legend()\n",
    "\n",
    "# Scores over time\n",
    "axes[1].plot(df.index, df['anomaly_score'], 'b-', alpha=0.7, label='Anomaly Score')\n",
    "axes[1].scatter(df.index[df['is_anomaly']], df.loc[df['is_anomaly'], 'anomaly_score'], \n",
    "                c='red', s=50, label='True Anomaly', zorder=5)\n",
    "\n",
    "# Add threshold line\n",
    "threshold = np.percentile(scores, 98)  # Top 2% as anomalies\n",
    "axes[1].axhline(y=threshold, color='orange', linestyle='--', label=f'Threshold (98th percentile: {threshold:.2f})')\n",
    "\n",
    "axes[1].set_xlabel('Sample Index')\n",
    "axes[1].set_ylabel('Anomaly Score')\n",
    "axes[1].set_title('Anomaly Scores Over Time')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "## Step 6: Evaluate Detection Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "def evaluate_threshold(scores, true_labels, threshold):\n",
    "    \"\"\"\n",
    "    Evaluate anomaly detection at a given threshold.\n",
    "    \"\"\"\n",
    "    predictions = (scores >= threshold).astype(int)\n",
    "    \n",
    "    precision = precision_score(true_labels, predictions)\n",
    "    recall = recall_score(true_labels, predictions)\n",
    "    f1 = f1_score(true_labels, predictions)\n",
    "    \n",
    "    return {\n",
    "        'threshold': threshold,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'predictions': predictions\n",
    "    }\n",
    "\n",
    "# Try different thresholds (percentile-based)\n",
    "true_labels = df['is_anomaly'].astype(int).values\n",
    "\n",
    "print(\"Threshold Analysis:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Percentile':<12} {'Threshold':<12} {'Precision':<12} {'Recall':<12} {'F1':<12}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for pct in [95, 96, 97, 98, 99]:\n",
    "    threshold = np.percentile(scores, pct)\n",
    "    result = evaluate_threshold(scores, true_labels, threshold)\n",
    "    print(f\"{pct}%          {threshold:<12.4f} {result['precision']:<12.4f} {result['recall']:<12.4f} {result['f1']:<12.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate AUC-ROC\n",
    "auc = roc_auc_score(true_labels, scores)\n",
    "print(f\"\\nAUC-ROC: {auc:.4f}\")\n",
    "\n",
    "# Use 98th percentile threshold for final evaluation\n",
    "best_threshold = np.percentile(scores, 98)\n",
    "final_result = evaluate_threshold(scores, true_labels, best_threshold)\n",
    "\n",
    "print(f\"\\nFinal Results (threshold = {best_threshold:.4f}):\")\n",
    "print(f\"  Precision: {final_result['precision']:.4f}\")\n",
    "print(f\"  Recall:    {final_result['recall']:.4f}\")\n",
    "print(f\"  F1 Score:  {final_result['f1']:.4f}\")\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(true_labels, final_result['predictions'])\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(f\"  TN: {cm[0,0]:5d}  FP: {cm[0,1]:5d}\")\n",
    "print(f\"  FN: {cm[1,0]:5d}  TP: {cm[1,1]:5d}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-25",
   "metadata": {},
   "source": [
    "## Step 7: Inspect Top Anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show top anomalies\n",
    "df_sorted = df.sort_values('anomaly_score', ascending=False)\n",
    "\n",
    "print(\"Top 15 Detected Anomalies:\")\n",
    "print(\"=\" * 80)\n",
    "print(df_sorted[['timestamp', 'cpu_usage', 'memory_usage', 'request_count', 'anomaly_score', 'is_anomaly']].head(15).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-27",
   "metadata": {},
   "source": [
    "## Step 8: Clean Up Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the endpoint\n",
    "print(f\"Deleting endpoint: {rcf_predictor.endpoint_name}\")\n",
    "rcf_predictor.delete_endpoint()\n",
    "print(\"Endpoint deleted successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-29",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "In this exercise, you learned:\n",
    "\n",
    "1. **Data Format**: CSV (no header) or RecordIO-protobuf\n",
    "\n",
    "2. **Key Hyperparameters**:\n",
    "   - `num_trees`: More trees = more stable scores (recommend 50-100)\n",
    "   - `num_samples_per_tree`: Inversely related to expected anomaly rate\n",
    "   - `feature_dim`: Number of input features\n",
    "\n",
    "3. **Output**: Anomaly scores (higher = more anomalous)\n",
    "\n",
    "4. **Threshold Selection**:\n",
    "   - Use percentile-based thresholds (e.g., 98th percentile)\n",
    "   - Tune based on precision/recall tradeoff\n",
    "   - Consider business cost of false positives vs missed anomalies\n",
    "\n",
    "5. **Evaluation Metrics**:\n",
    "   - AUC-ROC for overall performance\n",
    "   - Precision, Recall, F1 at specific threshold\n",
    "   - Confusion matrix for detailed analysis\n",
    "\n",
    "### Instance Recommendations\n",
    "\n",
    "| Task | Instance Types | Notes |\n",
    "|------|----------------|-------|\n",
    "| Training | ml.m5.large, ml.c5.xlarge | CPU only, very cost-effective |\n",
    "| Inference | ml.c5.large (recommended) | Low latency for streaming |\n",
    "\n",
    "### CloudWatch Training Metrics\n",
    "\n",
    "| Metric | Description |\n",
    "|--------|-------------|\n",
    "| `train:loss` | Training loss (should decrease) |\n",
    "| `validation:loss` | Validation loss |\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "- Start with `num_trees=100` for balance between speed and accuracy\n",
    "- Set `num_samples_per_tree` based on expected anomaly ratio (1/rate)\n",
    "- Monitor score distribution over time for drift\n",
    "- Consider streaming inference for real-time detection\n",
    "- Normalize features if they have very different scales\n",
    "\n",
    "### Anomaly Score Interpretation\n",
    "\n",
    "| Score Range | Typical Meaning |\n",
    "|-------------|-----------------|\n",
    "| < mean | Normal behavior |\n",
    "| mean to 95th percentile | Slightly unusual |\n",
    "| 95th to 99th percentile | Suspicious, investigate |\n",
    "| > 99th percentile | Highly anomalous, alert |\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Apply to real-world time series data\n",
    "- Implement streaming anomaly detection with Kinesis\n",
    "- Combine with CloudWatch Alarms for alerting\n",
    "- Use SageMaker Model Monitor for production monitoring\n",
    "- Consider ensemble with other anomaly detection methods"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
