{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# SageMaker LightGBM Classification Exercise\n",
    "\n",
    "This notebook walks you through training Amazon SageMaker's **LightGBM** algorithm on synthetic customer churn data.\n",
    "\n",
    "## What You'll Learn\n",
    "1. How to prepare data in LightGBM's required CSV format\n",
    "2. How to configure and train a LightGBM model on SageMaker\n",
    "3. How to use Batch Transform for predictions\n",
    "4. How to evaluate classification model performance\n",
    "\n",
    "## What is LightGBM?\n",
    "LightGBM (Light Gradient Boosting Machine) is an efficient, open-source implementation of Gradient Boosting Decision Tree (GBDT). Compared to XGBoost, LightGBM:\n",
    "- Uses **leaf-wise** tree growth (vs level-wise), which can be faster and more accurate\n",
    "- Uses **histogram-based** splitting for faster training\n",
    "- Is **memory-efficient** - SageMaker recommends general-purpose instances (M5) over compute-optimized (C5)\n",
    "- Supports **categorical features** natively without one-hot encoding\n",
    "\n",
    "## Prerequisites\n",
    "- SageMaker notebook instance or Studio, or local environment with AWS credentials\n",
    "- IAM role with S3 and SageMaker permissions\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Step 1: Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker import image_uris, model_uris, script_uris, hyperparameters\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.utils import name_from_base\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Configure AWS session from environment variables\n",
    "aws_profile = os.getenv('AWS_PROFILE')\n",
    "aws_region = os.getenv('AWS_REGION', 'us-west-2')\n",
    "sagemaker_role = os.getenv('SAGEMAKER_ROLE_ARN')\n",
    "\n",
    "if aws_profile:\n",
    "    boto3.setup_default_session(profile_name=aws_profile, region_name=aws_region)\n",
    "else:\n",
    "    boto3.setup_default_session(region_name=aws_region)\n",
    "\n",
    "# SageMaker session and role\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "# Use environment variable for role, or fall back to execution role if running in SageMaker\n",
    "if sagemaker_role:\n",
    "    role = sagemaker_role\n",
    "else:\n",
    "    role = get_execution_role()\n",
    "\n",
    "region = sagemaker_session.boto_region_name\n",
    "\n",
    "print(f\"AWS Profile: {aws_profile or 'default'}\")\n",
    "print(f\"SageMaker Role: {role}\")\n",
    "print(f\"Region: {region}\")\n",
    "print(f\"SageMaker SDK Version: {sagemaker.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "BUCKET_NAME = sagemaker_session.default_bucket()\n",
    "PREFIX = \"lightgbm-churn\"\n",
    "\n",
    "# Dataset parameters\n",
    "NUM_SAMPLES = 5000\n",
    "TEST_RATIO = 0.2\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "print(f\"S3 Bucket: {BUCKET_NAME}\")\n",
    "print(f\"S3 Prefix: {PREFIX}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## Step 2: Generate Synthetic Data\n",
    "\n",
    "We'll create a realistic customer churn dataset with:\n",
    "- Customer demographics (age, tenure)\n",
    "- Service usage patterns (monthly charges, support calls)\n",
    "- Contract and payment information\n",
    "- Binary churn target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_customer_churn_data(num_samples=5000, seed=42):\n",
    "    \"\"\"\n",
    "    Generate synthetic customer churn data for binary classification.\n",
    "    \n",
    "    Features are designed to have realistic relationships with churn:\n",
    "    - Short tenure increases churn risk\n",
    "    - Month-to-month contracts have higher churn\n",
    "    - High support calls indicate dissatisfaction\n",
    "    - Lack of tech support increases churn\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Customer demographics\n",
    "    age = np.random.normal(45, 15, num_samples).clip(18, 80)\n",
    "    tenure_months = np.random.exponential(24, num_samples).clip(1, 72)\n",
    "    \n",
    "    # Billing information\n",
    "    monthly_charges = np.random.normal(70, 30, num_samples).clip(20, 150)\n",
    "    total_charges = monthly_charges * tenure_months * np.random.uniform(0.9, 1.0, num_samples)\n",
    "    \n",
    "    # Service usage\n",
    "    num_products = np.random.poisson(2.5, num_samples).clip(1, 6)\n",
    "    support_calls = np.random.poisson(1.5, num_samples)\n",
    "    \n",
    "    # Contract type: 0=Month-to-month, 1=One year, 2=Two year\n",
    "    contract_type = np.random.choice([0, 1, 2], num_samples, p=[0.5, 0.3, 0.2])\n",
    "    \n",
    "    # Payment method: 0=Electronic check, 1=Credit card, 2=Bank transfer, 3=Mailed check\n",
    "    payment_method = np.random.choice([0, 1, 2, 3], num_samples, p=[0.35, 0.25, 0.25, 0.15])\n",
    "    \n",
    "    # Binary features\n",
    "    has_tech_support = np.random.binomial(1, 0.4, num_samples)\n",
    "    paperless_billing = np.random.binomial(1, 0.6, num_samples)\n",
    "    auto_payment = np.random.binomial(1, 0.45, num_samples)\n",
    "    \n",
    "    # Generate churn based on realistic patterns\n",
    "    churn_score = (\n",
    "        -0.03 * tenure_months +           # Longer tenure = less churn\n",
    "        0.015 * monthly_charges +          # Higher charges = more churn\n",
    "        0.15 * support_calls +             # More support calls = more churn\n",
    "        0.8 * (contract_type == 0) +       # Month-to-month = high churn\n",
    "        0.4 * (payment_method == 0) +      # Electronic check = higher churn\n",
    "        -0.5 * has_tech_support +          # Tech support = less churn\n",
    "        -0.1 * num_products +              # More products = less churn\n",
    "        np.random.normal(0, 0.5, num_samples)  # Random noise\n",
    "    )\n",
    "    \n",
    "    # Convert to probability and generate labels\n",
    "    churn_prob = 1 / (1 + np.exp(-churn_score))\n",
    "    churn = (np.random.random(num_samples) < churn_prob).astype(int)\n",
    "    \n",
    "    # Combine features into array (label first for SageMaker format)\n",
    "    features = np.column_stack([\n",
    "        age, tenure_months, monthly_charges, total_charges,\n",
    "        num_products, support_calls, contract_type, payment_method,\n",
    "        has_tech_support, paperless_billing, auto_payment\n",
    "    ])\n",
    "    \n",
    "    feature_names = [\n",
    "        'age', 'tenure_months', 'monthly_charges', 'total_charges',\n",
    "        'num_products', 'support_calls', 'contract_type', 'payment_method',\n",
    "        'has_tech_support', 'paperless_billing', 'auto_payment'\n",
    "    ]\n",
    "    \n",
    "    # Indices of categorical features (0-indexed, excluding the label column)\n",
    "    categorical_indices = [6, 7, 8, 9, 10]  # contract_type, payment_method, has_tech_support, paperless_billing, auto_payment\n",
    "    \n",
    "    return features.astype(np.float32), churn.astype(np.float32), feature_names, categorical_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the dataset\n",
    "print(\"Generating synthetic customer churn data...\")\n",
    "X, y, feature_names, categorical_indices = generate_customer_churn_data(NUM_SAMPLES, RANDOM_STATE)\n",
    "\n",
    "print(f\"\\nDataset shape: {X.shape}\")\n",
    "print(f\"Churn rate: {y.mean():.1%}\")\n",
    "print(f\"Features: {feature_names}\")\n",
    "print(f\"Categorical feature indices: {categorical_indices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X, y, test_ratio=0.2, seed=42):\n",
    "    \"\"\"Split data into train and test sets, maintaining class distribution.\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    indices = np.random.permutation(len(y))\n",
    "    test_size = int(len(y) * test_ratio)\n",
    "    \n",
    "    test_idx = indices[:test_size]\n",
    "    train_idx = indices[test_size:]\n",
    "    \n",
    "    return X[train_idx], X[test_idx], y[train_idx], y[test_idx]\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = split_data(X, y, TEST_RATIO, RANDOM_STATE)\n",
    "\n",
    "print(f\"Training set: {len(y_train)} samples (churn rate: {y_train.mean():.1%})\")\n",
    "print(f\"Test set: {len(y_test)} samples (churn rate: {y_test.mean():.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## Step 3: Visualize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame for visualization\n",
    "df_viz = pd.DataFrame(X_train, columns=feature_names)\n",
    "df_viz['churn'] = y_train\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "# Churn distribution\n",
    "ax = axes[0, 0]\n",
    "churn_counts = df_viz['churn'].value_counts().sort_index()\n",
    "ax.bar(['No Churn', 'Churn'], churn_counts.values, color=['steelblue', 'coral'])\n",
    "ax.set_title('Churn Distribution', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Count')\n",
    "for i, v in enumerate(churn_counts.values):\n",
    "    ax.text(i, v + 50, f'{v}\\n({v/len(df_viz):.1%})', ha='center')\n",
    "\n",
    "# Tenure by churn\n",
    "ax = axes[0, 1]\n",
    "df_viz[df_viz['churn']==0]['tenure_months'].hist(bins=30, alpha=0.6, label='No Churn', ax=ax, color='steelblue')\n",
    "df_viz[df_viz['churn']==1]['tenure_months'].hist(bins=30, alpha=0.6, label='Churn', ax=ax, color='coral')\n",
    "ax.set_title('Tenure Distribution by Churn', fontsize=12, fontweight='bold')\n",
    "ax.set_xlabel('Tenure (months)')\n",
    "ax.legend()\n",
    "\n",
    "# Monthly charges by churn\n",
    "ax = axes[0, 2]\n",
    "df_viz[df_viz['churn']==0]['monthly_charges'].hist(bins=30, alpha=0.6, label='No Churn', ax=ax, color='steelblue')\n",
    "df_viz[df_viz['churn']==1]['monthly_charges'].hist(bins=30, alpha=0.6, label='Churn', ax=ax, color='coral')\n",
    "ax.set_title('Monthly Charges by Churn', fontsize=12, fontweight='bold')\n",
    "ax.set_xlabel('Monthly Charges ($)')\n",
    "ax.legend()\n",
    "\n",
    "# Contract type vs churn\n",
    "ax = axes[1, 0]\n",
    "contract_churn = df_viz.groupby('contract_type')['churn'].mean()\n",
    "contract_labels = ['Month-to-month', 'One year', 'Two year']\n",
    "ax.bar(contract_labels, contract_churn.values, color='steelblue')\n",
    "ax.set_title('Churn Rate by Contract Type', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Churn Rate')\n",
    "for i, v in enumerate(contract_churn.values):\n",
    "    ax.text(i, v + 0.02, f'{v:.1%}', ha='center')\n",
    "\n",
    "# Support calls vs churn\n",
    "ax = axes[1, 1]\n",
    "support_churn = df_viz.groupby('support_calls')['churn'].mean()\n",
    "ax.bar(support_churn.index, support_churn.values, color='coral')\n",
    "ax.set_title('Churn Rate by Support Calls', fontsize=12, fontweight='bold')\n",
    "ax.set_xlabel('Number of Support Calls')\n",
    "ax.set_ylabel('Churn Rate')\n",
    "\n",
    "# Tech support vs churn\n",
    "ax = axes[1, 2]\n",
    "tech_churn = df_viz.groupby('has_tech_support')['churn'].mean()\n",
    "ax.bar(['No Tech Support', 'Has Tech Support'], tech_churn.values, color=['coral', 'steelblue'])\n",
    "ax.set_title('Churn Rate by Tech Support', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Churn Rate')\n",
    "for i, v in enumerate(tech_churn.values):\n",
    "    ax.text(i, v + 0.02, f'{v:.1%}', ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey Observations:\")\n",
    "print(f\"- Month-to-month contracts have {contract_churn[0]:.1%} churn vs {contract_churn[2]:.1%} for two-year\")\n",
    "print(f\"- Customers without tech support churn at {tech_churn[0]:.1%} vs {tech_churn[1]:.1%} with support\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## Step 4: Prepare Data for SageMaker LightGBM\n",
    "\n",
    "SageMaker's LightGBM algorithm expects:\n",
    "- **Training data**: CSV format with target in the first column (no header)\n",
    "- **Inference data**: CSV format with features only (no target column)\n",
    "- **Categorical features** (optional): A JSON file listing column indices of categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create local data directory\n",
    "os.makedirs('data/train', exist_ok=True)\n",
    "os.makedirs('data/test', exist_ok=True)\n",
    "\n",
    "def save_csv_for_training(X, y, filepath):\n",
    "    \"\"\"Save data in SageMaker LightGBM CSV format (label first, no header).\"\"\"\n",
    "    data = np.column_stack([y.reshape(-1, 1), X])\n",
    "    np.savetxt(filepath, data, delimiter=',', fmt='%.6f')\n",
    "\n",
    "def save_csv_for_inference(X, filepath):\n",
    "    \"\"\"Save features only for batch transform inference.\"\"\"\n",
    "    np.savetxt(filepath, X, delimiter=',', fmt='%.6f')\n",
    "\n",
    "# Save training data (label + features)\n",
    "save_csv_for_training(X_train, y_train, 'data/train/train.csv')\n",
    "\n",
    "# Save test features only (for batch transform)\n",
    "save_csv_for_inference(X_test, 'data/test/test_features.csv')\n",
    "\n",
    "# Save test labels locally for evaluation\n",
    "np.savetxt('data/test/test_labels.csv', y_test, delimiter=',', fmt='%.0f')\n",
    "\n",
    "# Save categorical feature indices (optional but recommended for LightGBM)\n",
    "# Note: indices are 0-based and refer to feature columns AFTER the label column\n",
    "with open('data/train/categorical_index.json', 'w') as f:\n",
    "    json.dump({\"cat_index_list\": categorical_indices}, f)\n",
    "\n",
    "print(\"Data saved locally:\")\n",
    "print(f\"  - data/train/train.csv ({os.path.getsize('data/train/train.csv') / 1024:.1f} KB)\")\n",
    "print(f\"  - data/train/categorical_index.json\")\n",
    "print(f\"  - data/test/test_features.csv ({os.path.getsize('data/test/test_features.csv') / 1024:.1f} KB)\")\n",
    "print(f\"  - data/test/test_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the data format\n",
    "print(\"Sample training data (first 3 rows):\")\n",
    "print(\"Format: label, feature1, feature2, ..., feature11\")\n",
    "print(\"=\"*70)\n",
    "with open('data/train/train.csv', 'r') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i >= 3:\n",
    "            break\n",
    "        print(line.strip())\n",
    "\n",
    "print(\"\\nCategorical index file:\")\n",
    "with open('data/train/categorical_index.json', 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload to S3\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "# Upload training data and categorical index\n",
    "train_s3_path = f\"{PREFIX}/train/train.csv\"\n",
    "cat_index_s3_path = f\"{PREFIX}/train/categorical_index.json\"\n",
    "test_s3_path = f\"{PREFIX}/test/test_features.csv\"\n",
    "\n",
    "s3_client.upload_file('data/train/train.csv', BUCKET_NAME, train_s3_path)\n",
    "s3_client.upload_file('data/train/categorical_index.json', BUCKET_NAME, cat_index_s3_path)\n",
    "s3_client.upload_file('data/test/test_features.csv', BUCKET_NAME, test_s3_path)\n",
    "\n",
    "# LightGBM expects the training directory, not the file\n",
    "train_s3_uri = f\"s3://{BUCKET_NAME}/{PREFIX}/train\"\n",
    "test_s3_uri = f\"s3://{BUCKET_NAME}/{test_s3_path}\"\n",
    "\n",
    "print(\"Data uploaded to S3:\")\n",
    "print(f\"  Train directory: {train_s3_uri}\")\n",
    "print(f\"  Test file: {test_s3_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "## Step 5: Configure and Train the LightGBM Model\n",
    "\n",
    "### Key Hyperparameters\n",
    "\n",
    "**num_boost_round** (Required)\n",
    "- Number of boosting iterations (trees to build)\n",
    "- More rounds can improve accuracy but risk overfitting\n",
    "- Typical range: 100-1000\n",
    "\n",
    "**num_leaves**\n",
    "- Maximum number of leaves in one tree\n",
    "- Main parameter controlling model complexity\n",
    "- LightGBM uses leaf-wise growth, so this is more important than max_depth\n",
    "- Typical range: 20-100 (default: 31)\n",
    "- Higher values = more complex model, risk of overfitting\n",
    "\n",
    "**learning_rate**\n",
    "- Shrinkage rate to prevent overfitting\n",
    "- Lower values require more boosting rounds but generalize better\n",
    "- Typical range: 0.01-0.3 (default: 0.1)\n",
    "\n",
    "**max_depth**\n",
    "- Maximum depth of each tree\n",
    "- Use to limit tree complexity and prevent overfitting\n",
    "- Set to -1 for no limit (default)\n",
    "- Typical range: 3-12 when limiting\n",
    "\n",
    "**feature_fraction** (colsample_bytree)\n",
    "- Fraction of features used per tree\n",
    "- Adds randomness to prevent overfitting\n",
    "- Typical range: 0.5-1.0 (default: 1.0)\n",
    "\n",
    "**bagging_fraction** (subsample)\n",
    "- Fraction of training samples used per tree\n",
    "- Requires bagging_freq > 0 to take effect\n",
    "- Typical range: 0.5-1.0 (default: 1.0)\n",
    "\n",
    "**bagging_freq**\n",
    "- Frequency for bagging (0 = disabled)\n",
    "- Set to positive integer to enable bagging every k iterations\n",
    "- Typical value: 1-10\n",
    "\n",
    "**min_data_in_leaf**\n",
    "- Minimum number of samples in a leaf\n",
    "- Prevents learning overly specific patterns\n",
    "- Typical range: 10-100 (default: 20)\n",
    "\n",
    "**lambda_l1** (reg_alpha)\n",
    "- L1 regularization on leaf weights\n",
    "- Encourages sparsity\n",
    "- Default: 0\n",
    "\n",
    "**lambda_l2** (reg_lambda)\n",
    "- L2 regularization on leaf weights\n",
    "- Smooths weights, reduces overfitting\n",
    "- Default: 0\n",
    "\n",
    "**scale_pos_weight**\n",
    "- Weight of positive class for imbalanced datasets\n",
    "- Set to: sum(negative) / sum(positive)\n",
    "- Helps model pay attention to minority class\n",
    "\n",
    "### Evaluation Metrics\n",
    "\n",
    "SageMaker LightGBM automatically chooses metrics based on problem type:\n",
    "- **Binary classification**: binary cross entropy (binary_logloss)\n",
    "- **Multiclass classification**: multi-class cross entropy (multi_logloss)\n",
    "- **Regression**: root mean squared error (rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the LightGBM container image using JumpStart\n",
    "train_model_id = \"lightgbm-classification-model\"\n",
    "train_model_version = \"*\"\n",
    "training_instance_type = \"ml.m5.xlarge\"\n",
    "\n",
    "# Retrieve the Docker image URI\n",
    "train_image_uri = image_uris.retrieve(\n",
    "    region=region,\n",
    "    framework=None,\n",
    "    model_id=train_model_id,\n",
    "    model_version=train_model_version,\n",
    "    image_scope=\"training\",\n",
    "    instance_type=training_instance_type,\n",
    ")\n",
    "\n",
    "# Retrieve the training script URI\n",
    "train_source_uri = script_uris.retrieve(\n",
    "    model_id=train_model_id,\n",
    "    model_version=train_model_version,\n",
    "    script_scope=\"training\"\n",
    ")\n",
    "\n",
    "# Retrieve the pre-trained model URI (used as starting point)\n",
    "train_model_uri = model_uris.retrieve(\n",
    "    model_id=train_model_id,\n",
    "    model_version=train_model_version,\n",
    "    model_scope=\"training\"\n",
    ")\n",
    "\n",
    "print(f\"Training Image URI: {train_image_uri}\")\n",
    "print(f\"Training Script URI: {train_source_uri}\")\n",
    "print(f\"Model URI: {train_model_uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get default hyperparameters and customize\n",
    "default_hparams = hyperparameters.retrieve_default(\n",
    "    model_id=train_model_id,\n",
    "    model_version=train_model_version\n",
    ")\n",
    "\n",
    "print(\"Default hyperparameters:\")\n",
    "for k, v in default_hparams.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate scale_pos_weight for imbalanced data\n",
    "num_negative = (y_train == 0).sum()\n",
    "num_positive = (y_train == 1).sum()\n",
    "scale_pos_weight = num_negative / num_positive\n",
    "\n",
    "print(f\"Class distribution: {num_negative} negative, {num_positive} positive\")\n",
    "print(f\"Calculated scale_pos_weight: {scale_pos_weight:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customize hyperparameters\n",
    "hparams = default_hparams.copy()\n",
    "\n",
    "# Override with our custom values\n",
    "hparams[\"num_boost_round\"] = \"200\"\n",
    "hparams[\"num_leaves\"] = \"31\"\n",
    "hparams[\"learning_rate\"] = \"0.05\"\n",
    "hparams[\"max_depth\"] = \"6\"\n",
    "hparams[\"feature_fraction\"] = \"0.8\"\n",
    "hparams[\"bagging_fraction\"] = \"0.8\"\n",
    "hparams[\"bagging_freq\"] = \"5\"\n",
    "hparams[\"min_data_in_leaf\"] = \"20\"\n",
    "hparams[\"lambda_l1\"] = \"0.1\"\n",
    "hparams[\"lambda_l2\"] = \"1.0\"\n",
    "hparams[\"scale_pos_weight\"] = str(scale_pos_weight)\n",
    "\n",
    "print(\"Custom hyperparameters:\")\n",
    "for k, v in hparams.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the estimator\n",
    "training_job_name = name_from_base(f\"lightgbm-churn\")\n",
    "\n",
    "lightgbm_estimator = Estimator(\n",
    "    role=role,\n",
    "    image_uri=train_image_uri,\n",
    "    source_dir=train_source_uri,\n",
    "    model_uri=train_model_uri,\n",
    "    entry_point=\"transfer_learning.py\",\n",
    "    instance_count=1,\n",
    "    instance_type=training_instance_type,\n",
    "    max_run=3600,\n",
    "    hyperparameters=hparams,\n",
    "    output_path=f's3://{BUCKET_NAME}/{PREFIX}/output',\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    base_job_name='lightgbm-churn'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting training job...\")\n",
    "print(\"This will take approximately 3-5 minutes.\\n\")\n",
    "\n",
    "# Start training - pass the directory containing train.csv and categorical_index.json\n",
    "lightgbm_estimator.fit(\n",
    "    {\"training\": train_s3_uri},\n",
    "    logs=True,\n",
    "    job_name=training_job_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training job info\n",
    "print(f\"Training job completed: {training_job_name}\")\n",
    "print(f\"Model artifacts: {lightgbm_estimator.model_data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "## Step 6: Run Batch Transform\n",
    "\n",
    "Instead of deploying a real-time endpoint, we use Batch Transform for predictions on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create transformer from the trained model\n",
    "transformer = lightgbm_estimator.transformer(\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.large',\n",
    "    output_path=f's3://{BUCKET_NAME}/{PREFIX}/batch-predictions'\n",
    ")\n",
    "\n",
    "print(\"Starting batch transform job...\")\n",
    "print(\"This will take approximately 3-5 minutes.\\n\")\n",
    "\n",
    "# Run batch inference\n",
    "transformer.transform(\n",
    "    data=test_s3_uri,\n",
    "    content_type='text/csv',\n",
    "    split_type='Line',\n",
    "    wait=True\n",
    ")\n",
    "\n",
    "print(f\"\\nPredictions written to: {transformer.output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-24",
   "metadata": {},
   "source": [
    "## Step 7: Download and Parse Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download predictions from S3\n",
    "prediction_key = f\"{PREFIX}/batch-predictions/test_features.csv.out\"\n",
    "\n",
    "s3_client.download_file(BUCKET_NAME, prediction_key, 'data/predictions.csv')\n",
    "\n",
    "# Load predictions (LightGBM outputs probabilities for classification)\n",
    "y_pred_proba = np.loadtxt('data/predictions.csv')\n",
    "y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "\n",
    "print(f\"Loaded predictions for {len(y_pred)} samples\")\n",
    "print(f\"Prediction distribution: {np.bincount(y_pred)}\")\n",
    "print(f\"Probability range: [{y_pred_proba.min():.4f}, {y_pred_proba.max():.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-26",
   "metadata": {},
   "source": [
    "## Step 8: Evaluate Model Performance\n",
    "\n",
    "### Understanding Classification Metrics\n",
    "\n",
    "**Accuracy** - Percentage of correct predictions. Can be misleading with imbalanced classes.\n",
    "\n",
    "**Precision** - Of all customers predicted to churn, how many actually churned? High precision = few false alarms.\n",
    "\n",
    "**Recall (Sensitivity)** - Of all customers who actually churned, how many did we catch? High recall = we catch most churners.\n",
    "\n",
    "**F1 Score** - Harmonic mean of precision and recall. Balances both metrics.\n",
    "\n",
    "**AUC-ROC** - Area Under the Receiver Operating Characteristic curve. Measures discrimination ability across all thresholds. 0.5 = random, 1.0 = perfect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, confusion_matrix, classification_report,\n",
    "    roc_curve, precision_recall_curve, average_precision_score\n",
    ")\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "avg_precision = average_precision_score(y_test, y_pred_proba)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"MODEL EVALUATION RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nAccuracy:           {accuracy:.4f}\")\n",
    "print(f\"Precision:          {precision:.4f}\")\n",
    "print(f\"Recall:             {recall:.4f}\")\n",
    "print(f\"F1 Score:           {f1:.4f}\")\n",
    "print(f\"ROC AUC:            {auc:.4f}\")\n",
    "print(f\"Average Precision:  {avg_precision:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CLASSIFICATION REPORT\")\n",
    "print(\"=\"*60)\n",
    "print(classification_report(y_test, y_pred, target_names=['No Churn', 'Churn']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"CONFUSION MATRIX\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nTrue Negatives (correct no-churn):  {tn}\")\n",
    "print(f\"False Positives (false alarm):       {fp}\")\n",
    "print(f\"False Negatives (missed churn):      {fn}\")\n",
    "print(f\"True Positives (caught churn):       {tp}\")\n",
    "\n",
    "print(f\"\\nSpecificity (TN rate):  {tn / (tn + fp):.4f}\")\n",
    "print(f\"False Positive Rate:    {fp / (tn + fp):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "\n",
    "# 1. Confusion Matrix Heatmap\n",
    "ax = axes[0, 0]\n",
    "im = ax.imshow(cm, cmap='Blues')\n",
    "ax.set_xticks([0, 1])\n",
    "ax.set_yticks([0, 1])\n",
    "ax.set_xticklabels(['No Churn', 'Churn'])\n",
    "ax.set_yticklabels(['No Churn', 'Churn'])\n",
    "ax.set_xlabel('Predicted', fontsize=12)\n",
    "ax.set_ylabel('Actual', fontsize=12)\n",
    "ax.set_title('Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax.text(j, i, str(cm[i, j]), ha='center', va='center', fontsize=20, fontweight='bold')\n",
    "plt.colorbar(im, ax=ax)\n",
    "\n",
    "# 2. ROC Curve\n",
    "ax = axes[0, 1]\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "ax.plot(fpr, tpr, 'b-', linewidth=2, label=f'LightGBM (AUC = {auc:.3f})')\n",
    "ax.plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random')\n",
    "ax.fill_between(fpr, tpr, alpha=0.2)\n",
    "ax.set_xlabel('False Positive Rate', fontsize=12)\n",
    "ax.set_ylabel('True Positive Rate', fontsize=12)\n",
    "ax.set_title('ROC Curve', fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='lower right')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Precision-Recall Curve\n",
    "ax = axes[1, 0]\n",
    "precision_curve, recall_curve, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "ax.plot(recall_curve, precision_curve, 'b-', linewidth=2, label=f'LightGBM (AP = {avg_precision:.3f})')\n",
    "ax.axhline(y=y_test.mean(), color='k', linestyle='--', linewidth=1, label=f'Baseline ({y_test.mean():.2f})')\n",
    "ax.fill_between(recall_curve, precision_curve, alpha=0.2)\n",
    "ax.set_xlabel('Recall', fontsize=12)\n",
    "ax.set_ylabel('Precision', fontsize=12)\n",
    "ax.set_title('Precision-Recall Curve', fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='lower left')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Prediction Distribution\n",
    "ax = axes[1, 1]\n",
    "ax.hist(y_pred_proba[y_test == 0], bins=50, alpha=0.6, label='No Churn (Actual)', color='steelblue', density=True)\n",
    "ax.hist(y_pred_proba[y_test == 1], bins=50, alpha=0.6, label='Churn (Actual)', color='coral', density=True)\n",
    "ax.axvline(x=0.5, color='black', linestyle='--', linewidth=2, label='Threshold (0.5)')\n",
    "ax.set_xlabel('Predicted Churn Probability', fontsize=12)\n",
    "ax.set_ylabel('Density', fontsize=12)\n",
    "ax.set_title('Prediction Distribution', fontsize=14, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-30",
   "metadata": {},
   "source": [
    "## Step 9: Threshold Analysis\n",
    "\n",
    "The default threshold of 0.5 may not be optimal. Let's analyze how different thresholds affect precision and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze different thresholds\n",
    "thresholds = np.linspace(0.1, 0.9, 17)\n",
    "results = []\n",
    "\n",
    "for thresh in thresholds:\n",
    "    y_pred_thresh = (y_pred_proba >= thresh).astype(int)\n",
    "    results.append({\n",
    "        'threshold': thresh,\n",
    "        'precision': precision_score(y_test, y_pred_thresh, zero_division=0),\n",
    "        'recall': recall_score(y_test, y_pred_thresh, zero_division=0),\n",
    "        'f1': f1_score(y_test, y_pred_thresh, zero_division=0),\n",
    "        'predicted_positive': y_pred_thresh.sum()\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Find optimal thresholds\n",
    "best_f1_idx = results_df['f1'].idxmax()\n",
    "best_f1_thresh = results_df.loc[best_f1_idx, 'threshold']\n",
    "\n",
    "print(\"Threshold Analysis:\")\n",
    "print(results_df.to_string(index=False))\n",
    "print(f\"\\nOptimal threshold for F1 score: {best_f1_thresh:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize threshold trade-offs\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "ax.plot(results_df['threshold'], results_df['precision'], 'b-', linewidth=2, marker='o', label='Precision')\n",
    "ax.plot(results_df['threshold'], results_df['recall'], 'r-', linewidth=2, marker='s', label='Recall')\n",
    "ax.plot(results_df['threshold'], results_df['f1'], 'g-', linewidth=2, marker='^', label='F1 Score')\n",
    "ax.axvline(x=0.5, color='gray', linestyle='--', alpha=0.7, label='Default (0.5)')\n",
    "ax.axvline(x=best_f1_thresh, color='green', linestyle=':', linewidth=2, label=f'Best F1 ({best_f1_thresh:.2f})')\n",
    "\n",
    "ax.set_xlabel('Classification Threshold', fontsize=12)\n",
    "ax.set_ylabel('Score', fontsize=12)\n",
    "ax.set_title('Precision-Recall Trade-off by Threshold', fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='center right')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_xlim(0.05, 0.95)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nBusiness Considerations:\")\n",
    "print(\"- Lower threshold: Catch more churners (high recall) but more false alarms (low precision)\")\n",
    "print(\"- Higher threshold: Fewer false alarms (high precision) but miss more churners (low recall)\")\n",
    "print(\"- Choose based on: cost of intervention vs cost of losing a customer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-33",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "In this exercise, you learned:\n",
    "\n",
    "1. **Data Format**: SageMaker LightGBM expects CSV format with the label in the first column (no header). Optionally, provide a `categorical_index.json` file to specify categorical feature indices.\n",
    "\n",
    "2. **Key Differences from XGBoost**:\n",
    "   - **Leaf-wise growth**: LightGBM grows trees leaf-wise (best-first) vs XGBoost's level-wise growth\n",
    "   - **num_leaves**: Main complexity parameter (vs max_depth in XGBoost)\n",
    "   - **Native categorical support**: No need for one-hot encoding\n",
    "   - **Memory-bound**: Use general-purpose instances (M5) not compute-optimized (C5)\n",
    "\n",
    "3. **Key Hyperparameters**:\n",
    "   - `num_boost_round`: Number of boosting iterations\n",
    "   - `num_leaves`: Maximum leaves per tree (main complexity control)\n",
    "   - `learning_rate`: Shrinkage rate\n",
    "   - `feature_fraction`, `bagging_fraction`: Sampling for regularization\n",
    "   - `scale_pos_weight`: Handle class imbalance\n",
    "\n",
    "4. **Evaluation**: Use AUC-ROC for imbalanced datasets. Tune threshold based on business costs of false positives vs false negatives.\n",
    "\n",
    "## LightGBM vs XGBoost: When to Use Which?\n",
    "\n",
    "| Aspect | LightGBM | XGBoost |\n",
    "|--------|----------|----------|\n",
    "| Speed | Faster (histogram-based) | Slower but more mature |\n",
    "| Memory | More efficient | Higher memory usage |\n",
    "| Large datasets | Better scaling | Can struggle |\n",
    "| Small datasets | Risk of overfitting | Often better |\n",
    "| Categorical features | Native support | Requires encoding |\n",
    "| Tree growth | Leaf-wise (faster) | Level-wise (more balanced) |\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Experiment with different hyperparameters\n",
    "- Try SageMaker Hyperparameter Tuning for automatic optimization\n",
    "- Compare performance with XGBoost on your data\n",
    "- Use early stopping with validation data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
