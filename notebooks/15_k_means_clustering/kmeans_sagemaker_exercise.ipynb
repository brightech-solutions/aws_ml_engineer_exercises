{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# SageMaker K-Means Clustering Exercise\n",
    "\n",
    "This notebook demonstrates Amazon SageMaker's **K-Means** algorithm for unsupervised clustering.\n",
    "\n",
    "## What You'll Learn\n",
    "1. How to prepare data for clustering\n",
    "2. How to configure and understand K-Means hyperparameters\n",
    "3. How to train a K-Means model\n",
    "4. How to interpret cluster assignments and evaluate clustering quality\n",
    "\n",
    "## What is K-Means?\n",
    "\n",
    "K-Means is an **unsupervised** algorithm that groups data points into k clusters by:\n",
    "1. Initializing k cluster centroids (randomly or kmeans++)\n",
    "2. Assigning each point to nearest centroid\n",
    "3. Updating centroids to cluster means\n",
    "4. Repeating until convergence\n",
    "\n",
    "**SageMaker's Implementation:**\n",
    "- Web-scale algorithm (handles billions of points)\n",
    "- Single-pass streaming for efficiency\n",
    "- GPU acceleration available\n",
    "- Mini-batch variant for speed\n",
    "\n",
    "## Use Cases\n",
    "\n",
    "| Application | Description |\n",
    "|-------------|-------------|\n",
    "| Customer segmentation | Group customers by behavior |\n",
    "| Anomaly detection | Find outliers far from centroids |\n",
    "| Image compression | Reduce color palette |\n",
    "| Document clustering | Group similar documents |\n",
    "| Feature engineering | Create cluster membership features |\n",
    "\n",
    "---\n",
    "\n",
    "## ⚠️ Training Cost Information\n",
    "\n",
    "<div style=\"background-color: #010302ff; border: 1px solid #28a745; border-radius: 5px; padding: 15px; margin: 10px 0;\">\n",
    "\n",
    "### K-Means Supports CPU and GPU\n",
    "\n",
    "K-Means is computationally efficient. GPU helps with very large datasets.\n",
    "\n",
    "| Instance Type | Type | On-Demand Price* | Best For |\n",
    "|---------------|------|------------------|----------|\n",
    "| ml.m5.large | CPU | ~$0.13/hour | Small datasets (<1M samples) |\n",
    "| ml.c5.xlarge | CPU | ~$0.24/hour | Medium datasets |\n",
    "| ml.g4dn.xlarge | GPU | ~$0.74/hour | Large datasets (>1M samples) |\n",
    "| ml.p3.2xlarge | GPU | ~$3.83/hour | Very large datasets |\n",
    "\n",
    "*Prices are approximate for us-west-2.\n",
    "\n",
    "### Cost Estimation\n",
    "- **Training**: Very fast! Usually 2-5 minutes (~$0.01-0.03)\n",
    "- **Inference endpoint**: ~$0.13/hour for ml.m5.large\n",
    "- K-Means is one of the most cost-effective SageMaker algorithms\n",
    "\n",
    "### Key Advantage\n",
    "SageMaker K-Means uses streaming single-pass algorithm - it can handle datasets that don't fit in memory!\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Step 1: Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.image_uris import retrieve\n",
    "from sagemaker.estimator import Estimator\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Configure AWS session from environment variables\n",
    "aws_profile = os.getenv('AWS_PROFILE')\n",
    "aws_region = os.getenv('AWS_REGION', 'us-west-2')\n",
    "sagemaker_role = os.getenv('SAGEMAKER_ROLE_ARN')\n",
    "\n",
    "if aws_profile:\n",
    "    boto3.setup_default_session(profile_name=aws_profile, region_name=aws_region)\n",
    "else:\n",
    "    boto3.setup_default_session(region_name=aws_region)\n",
    "\n",
    "# SageMaker session and role\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "if sagemaker_role:\n",
    "    role = sagemaker_role\n",
    "else:\n",
    "    role = get_execution_role()\n",
    "\n",
    "region = sagemaker_session.boto_region_name\n",
    "\n",
    "print(f\"AWS Profile: {aws_profile or 'default'}\")\n",
    "print(f\"SageMaker Role: {role}\")\n",
    "print(f\"Region: {region}\")\n",
    "print(f\"SageMaker SDK Version: {sagemaker.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "BUCKET_NAME = sagemaker_session.default_bucket()\n",
    "PREFIX = \"kmeans\"\n",
    "\n",
    "# Dataset parameters\n",
    "NUM_SAMPLES = 5000\n",
    "NUM_FEATURES = 10\n",
    "NUM_CLUSTERS = 5\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "print(f\"S3 Bucket: {BUCKET_NAME}\")\n",
    "print(f\"S3 Prefix: {PREFIX}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## Step 2: Generate Synthetic Clustering Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate clustered data\n",
    "X, y_true = make_blobs(\n",
    "    n_samples=NUM_SAMPLES,\n",
    "    n_features=NUM_FEATURES,\n",
    "    centers=NUM_CLUSTERS,\n",
    "    cluster_std=1.5,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "X = X.astype(np.float32)\n",
    "\n",
    "print(f\"Data shape: {X.shape}\")\n",
    "print(f\"True clusters: {NUM_CLUSTERS}\")\n",
    "print(f\"\\nTrue cluster distribution:\")\n",
    "unique, counts = np.unique(y_true, return_counts=True)\n",
    "for c, n in zip(unique, counts):\n",
    "    print(f\"  Cluster {c}: {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize first two dimensions\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "\n",
    "scatter = ax.scatter(X[:, 0], X[:, 1], c=y_true, cmap='tab10', alpha=0.6)\n",
    "ax.set_xlabel('Feature 0')\n",
    "ax.set_ylabel('Feature 1')\n",
    "ax.set_title('True Clusters (First 2 Features)')\n",
    "plt.colorbar(scatter, ax=ax, label='Cluster')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## Step 3: Prepare Data for K-Means\n",
    "\n",
    "K-Means expects features only (no labels) in CSV or RecordIO format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as CSV (no header, features only)\n",
    "os.makedirs('data/kmeans', exist_ok=True)\n",
    "\n",
    "np.savetxt('data/kmeans/train.csv', X, delimiter=',')\n",
    "\n",
    "print(f\"Saved: data/kmeans/train.csv ({os.path.getsize('data/kmeans/train.csv') / 1024:.1f} KB)\")\n",
    "\n",
    "# Preview\n",
    "print(\"\\nFile preview (first 3 lines):\")\n",
    "with open('data/kmeans/train.csv', 'r') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i >= 3:\n",
    "            break\n",
    "        print(f\"  {line.strip()[:80]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload to S3\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "train_s3_key = f\"{PREFIX}/train/train.csv\"\n",
    "s3_client.upload_file('data/kmeans/train.csv', BUCKET_NAME, train_s3_key)\n",
    "\n",
    "train_uri = f\"s3://{BUCKET_NAME}/{PREFIX}/train\"\n",
    "print(f\"Data uploaded to: {train_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## Step 4: Train K-Means Model\n",
    "\n",
    "### Understanding K-Means Hyperparameters\n",
    "\n",
    "| Parameter | Description | Default | Recommendation |\n",
    "|-----------|-------------|---------|----------------|\n",
    "| `k` | Number of clusters | Required | Use elbow/silhouette method |\n",
    "| `feature_dim` | Number of features | Required | Must match data |\n",
    "| `mini_batch_size` | Batch size | 5000 | 1000-10000 |\n",
    "| `epochs` | Training passes | 1 | 1-10 |\n",
    "| `init_method` | Initialization | random | `random` or `kmeans++` |\n",
    "| `extra_center_factor` | Extra centers during training | 1 | 1-10 for stability |\n",
    "| `eval_metrics` | Metrics to compute | None | `msd`, `ssd` |\n",
    "| `half_life_time_size` | For streaming (decay factor) | 0 | For concept drift |\n",
    "| `local_lloyd_max_iter` | Max Lloyd iterations | 300 | Usually sufficient |\n",
    "| `local_lloyd_tol` | Convergence tolerance | 0.0001 | Lower = more precision |\n",
    "| `local_lloyd_init_method` | Local initialization | kmeans++ | kmeans++, random |\n",
    "\n",
    "### Key Hyperparameter Details\n",
    "\n",
    "**k (Number of Clusters)**\n",
    "- Most critical parameter\n",
    "- Too few → heterogeneous clusters\n",
    "- Too many → fragmented, meaningless clusters\n",
    "- Use **Elbow Method** or **Silhouette Score** to determine optimal k\n",
    "- Start with estimated number of natural groups\n",
    "\n",
    "**init_method**\n",
    "- `random`: Random initialization (faster, less stable)\n",
    "- `kmeans++`: Smart initialization (more stable, slightly slower)\n",
    "- **Recommendation**: Always use `kmeans++` unless speed is critical\n",
    "\n",
    "**extra_center_factor**\n",
    "- Creates k × extra_center_factor centers during training\n",
    "- Reduces to k at the end\n",
    "- Higher values = more stable results, longer training\n",
    "- Use 2-5 for better quality\n",
    "\n",
    "**mini_batch_size**\n",
    "- Larger = faster training, potentially less accurate\n",
    "- Smaller = slower, potentially better clusters\n",
    "- SageMaker streams data, so batch size affects memory, not data size\n",
    "\n",
    "### Evaluation Metrics\n",
    "\n",
    "| Metric | Description | Good Values |\n",
    "|--------|-------------|-------------|\n",
    "| `msd` | Mean Squared Distance to centroid | Lower is better |\n",
    "| `ssd` | Sum of Squared Distances (Inertia) | Lower is better |\n",
    "| Silhouette Score | Cluster separation quality | Closer to 1 is better |\n",
    "\n",
    "### CloudWatch Training Metrics\n",
    "\n",
    "| Metric | Description |\n",
    "|--------|-------------|\n",
    "| `train:msd` | Training mean squared distance |\n",
    "| `test:msd` | Test mean squared distance |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get K-Means container image\n",
    "kmeans_image = retrieve(\n",
    "    framework='kmeans',\n",
    "    region=region,\n",
    "    version='1'\n",
    ")\n",
    "\n",
    "print(f\"K-Means Image URI: {kmeans_image}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create K-Means estimator\n",
    "kmeans_estimator = Estimator(\n",
    "    image_uri=kmeans_image,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.large',\n",
    "    output_path=f's3://{BUCKET_NAME}/{PREFIX}/output',\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    base_job_name='kmeans'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyperparameters\n",
    "hyperparameters = {\n",
    "    \"k\": NUM_CLUSTERS,\n",
    "    \"feature_dim\": NUM_FEATURES,\n",
    "    \"mini_batch_size\": 500,\n",
    "    \"epochs\": 10,\n",
    "    \"init_method\": \"random\",\n",
    "    \"extra_center_factor\": 2,\n",
    "}\n",
    "\n",
    "kmeans_estimator.set_hyperparameters(**hyperparameters)\n",
    "\n",
    "print(\"K-Means hyperparameters:\")\n",
    "for k, v in hyperparameters.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "print(\"Starting K-Means training job...\")\n",
    "print(\"This will take approximately 3-5 minutes.\\n\")\n",
    "\n",
    "kmeans_estimator.fit(\n",
    "    {'train': train_uri},\n",
    "    wait=True,\n",
    "    logs=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training job info\n",
    "job_name = kmeans_estimator.latest_training_job.name\n",
    "print(f\"Training job completed: {job_name}\")\n",
    "print(f\"Model artifacts: {kmeans_estimator.model_data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## Step 5: Deploy and Get Cluster Assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy the model\n",
    "print(\"Deploying K-Means model...\")\n",
    "print(\"This will take approximately 5-7 minutes.\\n\")\n",
    "\n",
    "kmeans_predictor = kmeans_estimator.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m5.large',\n",
    "    endpoint_name=f'kmeans-{datetime.now().strftime(\"%Y%m%d%H%M\")}'\n",
    ")\n",
    "\n",
    "print(f\"\\nEndpoint deployed: {kmeans_predictor.endpoint_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "# Configure predictor\n",
    "kmeans_predictor.serializer = CSVSerializer()\n",
    "kmeans_predictor.deserializer = JSONDeserializer()\n",
    "\n",
    "def get_cluster_assignments(data, predictor, batch_size=500):\n",
    "    \"\"\"\n",
    "    Get cluster assignments for data.\n",
    "    \n",
    "    Returns:\n",
    "        clusters: Cluster IDs\n",
    "        distances: Distance to assigned centroid\n",
    "    \"\"\"\n",
    "    clusters = []\n",
    "    distances = []\n",
    "    \n",
    "    for i in range(0, len(data), batch_size):\n",
    "        batch = data[i:i+batch_size]\n",
    "        response = predictor.predict(batch)\n",
    "        \n",
    "        for pred in response['predictions']:\n",
    "            clusters.append(pred['closest_cluster'])\n",
    "            distances.append(pred['distance_to_cluster'])\n",
    "    \n",
    "    return np.array(clusters), np.array(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cluster assignments\n",
    "print(\"Getting cluster assignments...\")\n",
    "predicted_clusters, distances = get_cluster_assignments(X, kmeans_predictor)\n",
    "\n",
    "print(f\"\\nPredicted cluster distribution:\")\n",
    "unique, counts = np.unique(predicted_clusters, return_counts=True)\n",
    "for c, n in zip(unique, counts):\n",
    "    print(f\"  Cluster {c}: {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "## Step 6: Evaluate Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate silhouette score\n",
    "silhouette = silhouette_score(X, predicted_clusters)\n",
    "\n",
    "# Calculate inertia (sum of squared distances to centroids)\n",
    "inertia = np.sum(distances ** 2)\n",
    "\n",
    "print(\"Clustering Metrics:\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Silhouette Score: {silhouette:.4f}\")\n",
    "print(f\"Inertia (SSE): {inertia:.2f}\")\n",
    "print(f\"Average distance to centroid: {np.mean(distances):.4f}\")\n",
    "print(f\"\\nSilhouette Score Interpretation:\")\n",
    "print(f\"  -1 to 0: Poor clustering\")\n",
    "print(f\"  0 to 0.5: Overlapping clusters\")\n",
    "print(f\"  0.5 to 1: Dense, well-separated clusters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predicted clusters\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# True clusters\n",
    "scatter1 = axes[0].scatter(X[:, 0], X[:, 1], c=y_true, cmap='tab10', alpha=0.6)\n",
    "axes[0].set_xlabel('Feature 0')\n",
    "axes[0].set_ylabel('Feature 1')\n",
    "axes[0].set_title('True Clusters')\n",
    "plt.colorbar(scatter1, ax=axes[0])\n",
    "\n",
    "# Predicted clusters\n",
    "scatter2 = axes[1].scatter(X[:, 0], X[:, 1], c=predicted_clusters, cmap='tab10', alpha=0.6)\n",
    "axes[1].set_xlabel('Feature 0')\n",
    "axes[1].set_ylabel('Feature 1')\n",
    "axes[1].set_title(f'Predicted Clusters (Silhouette: {silhouette:.3f})')\n",
    "plt.colorbar(scatter2, ax=axes[1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distance distribution by cluster\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "for c in range(NUM_CLUSTERS):\n",
    "    mask = predicted_clusters == c\n",
    "    ax.hist(distances[mask], bins=30, alpha=0.5, label=f'Cluster {c}')\n",
    "\n",
    "ax.set_xlabel('Distance to Centroid')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Distance Distribution by Cluster')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-24",
   "metadata": {},
   "source": [
    "## Step 7: Choosing k (Elbow Method)\n",
    "\n",
    "In practice, you would train multiple models with different k values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-25",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "Choosing the Number of Clusters (k):\n",
    "====================================\n",
    "\n",
    "1. Elbow Method:\n",
    "   - Plot inertia vs k\n",
    "   - Look for \"elbow\" where improvement slows\n",
    "\n",
    "2. Silhouette Method:\n",
    "   - Plot silhouette score vs k\n",
    "   - Choose k with highest score\n",
    "\n",
    "3. Domain Knowledge:\n",
    "   - Customer segments: Often 3-7\n",
    "   - Product categories: Based on business needs\n",
    "\n",
    "4. Gap Statistic:\n",
    "   - Compare clustering to random reference\n",
    "   - More statistically rigorous\n",
    "\n",
    "For production, train multiple models:\n",
    "- k = 3, 4, 5, 6, 7, 8, 9, 10\n",
    "- Evaluate each with silhouette score\n",
    "- Consider business interpretability\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-26",
   "metadata": {},
   "source": [
    "## Step 8: Clean Up Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the endpoint\n",
    "print(f\"Deleting endpoint: {kmeans_predictor.endpoint_name}\")\n",
    "kmeans_predictor.delete_endpoint()\n",
    "print(\"Endpoint deleted successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-28",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "In this exercise, you learned:\n",
    "\n",
    "1. **Data Format**: CSV with features only (no labels)\n",
    "\n",
    "2. **Key Hyperparameters**:\n",
    "   - `k`: Number of clusters (most critical)\n",
    "   - `feature_dim`: Number of features\n",
    "   - `init_method`: Initialization strategy (use `kmeans++`)\n",
    "   - `extra_center_factor`: For more stable results\n",
    "   - `epochs`: Number of passes (1 usually sufficient)\n",
    "\n",
    "3. **Output**:\n",
    "   - `closest_cluster`: Assigned cluster ID\n",
    "   - `distance_to_cluster`: Distance to centroid\n",
    "\n",
    "4. **Evaluation Metrics**:\n",
    "   - Silhouette score (-1 to 1, higher is better)\n",
    "   - Inertia/SSE (lower is better)\n",
    "   - Mean squared distance to centroid\n",
    "\n",
    "### Instance Recommendations\n",
    "\n",
    "| Task | Instance Types | Notes |\n",
    "|------|----------------|-------|\n",
    "| Training (small) | ml.m5.large | CPU, <1M samples |\n",
    "| Training (large) | ml.g4dn.xlarge | GPU, >1M samples |\n",
    "| Inference | ml.m5.large, ml.c5.large | CPU sufficient |\n",
    "\n",
    "### Methods to Choose k\n",
    "\n",
    "| Method | Description | When to Use |\n",
    "|--------|-------------|-------------|\n",
    "| **Elbow Method** | Plot inertia vs k, find \"elbow\" | Quick visual check |\n",
    "| **Silhouette Score** | Plot score vs k, maximize | More rigorous |\n",
    "| **Gap Statistic** | Compare to random reference | Statistical approach |\n",
    "| **Domain Knowledge** | Business understanding | When you know expected groups |\n",
    "\n",
    "### Silhouette Score Interpretation\n",
    "\n",
    "| Score Range | Meaning |\n",
    "|-------------|---------|\n",
    "| 0.71 - 1.00 | Strong structure |\n",
    "| 0.51 - 0.70 | Reasonable structure |\n",
    "| 0.26 - 0.50 | Weak structure, try different k |\n",
    "| < 0.25 | No substantial structure |\n",
    "\n",
    "### SageMaker K-Means Advantages\n",
    "\n",
    "- Handles billions of data points\n",
    "- Single-pass streaming algorithm\n",
    "- GPU acceleration\n",
    "- Distributed training\n",
    "- Mini-batch for memory efficiency\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "1. **Scale features**: K-Means is distance-based, normalize features!\n",
    "2. **Use kmeans++**: Better initialization = better results\n",
    "3. **Try multiple k values**: Use elbow/silhouette to find optimal\n",
    "4. **Increase epochs** if clusters seem unstable\n",
    "5. **Check cluster sizes**: Very uneven sizes may indicate poor k\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Try different k values with elbow/silhouette method\n",
    "- Use cluster assignments as features for downstream models\n",
    "- Combine with PCA for visualization\n",
    "- Apply to customer segmentation use case\n",
    "- Compare with other clustering algorithms (DBSCAN, hierarchical)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
