{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# SageMaker XGBoost Classification Exercise\n",
    "\n",
    "This notebook walks you through training Amazon SageMaker's **XGBoost** algorithm on synthetic customer churn data.\n",
    "\n",
    "## What You'll Learn\n",
    "1. How to prepare data in XGBoost's required CSV format\n",
    "2. How to configure and train an XGBoost model on SageMaker\n",
    "3. How to use Batch Transform for predictions\n",
    "4. How to evaluate classification model performance\n",
    "\n",
    "## Prerequisites\n",
    "- SageMaker notebook instance or Studio, or local environment with AWS credentials\n",
    "- IAM role with S3 and SageMaker permissions\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Step 1: Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/david.jarmoluk/Library/Application Support/sagemaker/config.yaml\n",
      "AWS Profile: brightech-secondary\n",
      "SageMaker Role: arn:aws:iam::096816224238:role/service-role/AmazonSageMaker-ExecutionRole-20251113T125927\n",
      "Region: us-west-2\n",
      "SageMaker SDK Version: 2.255.0\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.image_uris import retrieve\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.inputs import TrainingInput\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Configure AWS session from environment variables\n",
    "aws_profile = os.getenv('AWS_PROFILE')\n",
    "aws_region = os.getenv('AWS_REGION', 'us-west-2')\n",
    "sagemaker_role = os.getenv('SAGEMAKER_ROLE_ARN')\n",
    "\n",
    "if aws_profile:\n",
    "    boto3.setup_default_session(profile_name=aws_profile, region_name=aws_region)\n",
    "else:\n",
    "    boto3.setup_default_session(region_name=aws_region)\n",
    "\n",
    "# SageMaker session and role\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "# Use environment variable for role, or fall back to execution role if running in SageMaker\n",
    "if sagemaker_role:\n",
    "    role = sagemaker_role\n",
    "else:\n",
    "    role = get_execution_role()\n",
    "\n",
    "region = sagemaker_session.boto_region_name\n",
    "\n",
    "print(f\"AWS Profile: {aws_profile or 'default'}\")\n",
    "print(f\"SageMaker Role: {role}\")\n",
    "print(f\"Region: {region}\")\n",
    "print(f\"SageMaker SDK Version: {sagemaker.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 Bucket: sagemaker-us-west-2-096816224238\n",
      "S3 Prefix: xgboost\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "BUCKET_NAME = sagemaker_session.default_bucket()\n",
    "PREFIX = \"xgboost\"\n",
    "\n",
    "# Dataset parameters\n",
    "NUM_SAMPLES = 5000\n",
    "TEST_RATIO = 0.2\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "print(f\"S3 Bucket: {BUCKET_NAME}\")\n",
    "print(f\"S3 Prefix: {PREFIX}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## Step 2: Generate Synthetic Data\n",
    "\n",
    "We'll create a realistic customer churn dataset with:\n",
    "- Customer demographics (age, tenure)\n",
    "- Service usage patterns (monthly charges, support calls)\n",
    "- Contract and payment information\n",
    "- Binary churn target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_customer_churn_data(num_samples=5000, seed=42):\n",
    "    \"\"\"\n",
    "    Generate synthetic customer churn data for binary classification.\n",
    "    \n",
    "    Features are designed to have realistic relationships with churn:\n",
    "    - Short tenure increases churn risk\n",
    "    - Month-to-month contracts have higher churn\n",
    "    - High support calls indicate dissatisfaction\n",
    "    - Lack of tech support increases churn\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Customer demographics\n",
    "    age = np.random.normal(45, 15, num_samples).clip(18, 80)\n",
    "    tenure_months = np.random.exponential(24, num_samples).clip(1, 72)\n",
    "    \n",
    "    # Billing information\n",
    "    monthly_charges = np.random.normal(70, 30, num_samples).clip(20, 150)\n",
    "    total_charges = monthly_charges * tenure_months * np.random.uniform(0.9, 1.0, num_samples)\n",
    "    \n",
    "    # Service usage\n",
    "    num_products = np.random.poisson(2.5, num_samples).clip(1, 6)\n",
    "    support_calls = np.random.poisson(1.5, num_samples)\n",
    "    \n",
    "    # Contract type: 0=Month-to-month, 1=One year, 2=Two year\n",
    "    contract_type = np.random.choice([0, 1, 2], num_samples, p=[0.5, 0.3, 0.2])\n",
    "    \n",
    "    # Payment method: 0=Electronic check, 1=Credit card, 2=Bank transfer, 3=Mailed check\n",
    "    payment_method = np.random.choice([0, 1, 2, 3], num_samples, p=[0.35, 0.25, 0.25, 0.15])\n",
    "    \n",
    "    # Binary features\n",
    "    has_tech_support = np.random.binomial(1, 0.4, num_samples)\n",
    "    paperless_billing = np.random.binomial(1, 0.6, num_samples)\n",
    "    auto_payment = np.random.binomial(1, 0.45, num_samples)\n",
    "    \n",
    "    # Generate churn based on realistic patterns\n",
    "    churn_score = (\n",
    "        -0.03 * tenure_months +           # Longer tenure = less churn\n",
    "        0.015 * monthly_charges +          # Higher charges = more churn\n",
    "        0.15 * support_calls +             # More support calls = more churn\n",
    "        0.8 * (contract_type == 0) +       # Month-to-month = high churn\n",
    "        0.4 * (payment_method == 0) +      # Electronic check = higher churn\n",
    "        -0.5 * has_tech_support +          # Tech support = less churn\n",
    "        -0.1 * num_products +              # More products = less churn\n",
    "        np.random.normal(0, 0.5, num_samples)  # Random noise\n",
    "    )\n",
    "    \n",
    "    # Convert to probability and generate labels\n",
    "    churn_prob = 1 / (1 + np.exp(-churn_score))\n",
    "    churn = (np.random.random(num_samples) < churn_prob).astype(int)\n",
    "    \n",
    "    # Combine features into array (label first for SageMaker format)\n",
    "    features = np.column_stack([\n",
    "        age, tenure_months, monthly_charges, total_charges,\n",
    "        num_products, support_calls, contract_type, payment_method,\n",
    "        has_tech_support, paperless_billing, auto_payment\n",
    "    ])\n",
    "    \n",
    "    feature_names = [\n",
    "        'age', 'tenure_months', 'monthly_charges', 'total_charges',\n",
    "        'num_products', 'support_calls', 'contract_type', 'payment_method',\n",
    "        'has_tech_support', 'paperless_billing', 'auto_payment'\n",
    "    ]\n",
    "    \n",
    "    return features.astype(np.float32), churn.astype(np.float32), feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the dataset\n",
    "print(\"Generating synthetic customer churn data...\")\n",
    "X, y, feature_names = generate_customer_churn_data(NUM_SAMPLES, RANDOM_STATE)\n",
    "\n",
    "print(f\"\\nDataset shape: {X.shape}\")\n",
    "print(f\"Churn rate: {y.mean():.1%}\")\n",
    "print(f\"Features: {feature_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X, y, test_ratio=0.2, seed=42):\n",
    "    \"\"\"Split data into train and test sets, maintaining class distribution.\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    indices = np.random.permutation(len(y))\n",
    "    test_size = int(len(y) * test_ratio)\n",
    "    \n",
    "    test_idx = indices[:test_size]\n",
    "    train_idx = indices[test_size:]\n",
    "    \n",
    "    return X[train_idx], X[test_idx], y[train_idx], y[test_idx]\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = split_data(X, y, TEST_RATIO, RANDOM_STATE)\n",
    "\n",
    "print(f\"Training set: {len(y_train)} samples (churn rate: {y_train.mean():.1%})\")\n",
    "print(f\"Test set: {len(y_test)} samples (churn rate: {y_test.mean():.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## Step 3: Visualize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame for visualization\n",
    "df_viz = pd.DataFrame(X_train, columns=feature_names)\n",
    "df_viz['churn'] = y_train\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "# Churn distribution\n",
    "ax = axes[0, 0]\n",
    "churn_counts = df_viz['churn'].value_counts().sort_index()\n",
    "ax.bar(['No Churn', 'Churn'], churn_counts.values, color=['steelblue', 'coral'])\n",
    "ax.set_title('Churn Distribution', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Count')\n",
    "for i, v in enumerate(churn_counts.values):\n",
    "    ax.text(i, v + 50, f'{v}\\n({v/len(df_viz):.1%})', ha='center')\n",
    "\n",
    "# Tenure by churn\n",
    "ax = axes[0, 1]\n",
    "df_viz[df_viz['churn']==0]['tenure_months'].hist(bins=30, alpha=0.6, label='No Churn', ax=ax, color='steelblue')\n",
    "df_viz[df_viz['churn']==1]['tenure_months'].hist(bins=30, alpha=0.6, label='Churn', ax=ax, color='coral')\n",
    "ax.set_title('Tenure Distribution by Churn', fontsize=12, fontweight='bold')\n",
    "ax.set_xlabel('Tenure (months)')\n",
    "ax.legend()\n",
    "\n",
    "# Monthly charges by churn\n",
    "ax = axes[0, 2]\n",
    "df_viz[df_viz['churn']==0]['monthly_charges'].hist(bins=30, alpha=0.6, label='No Churn', ax=ax, color='steelblue')\n",
    "df_viz[df_viz['churn']==1]['monthly_charges'].hist(bins=30, alpha=0.6, label='Churn', ax=ax, color='coral')\n",
    "ax.set_title('Monthly Charges by Churn', fontsize=12, fontweight='bold')\n",
    "ax.set_xlabel('Monthly Charges ($)')\n",
    "ax.legend()\n",
    "\n",
    "# Contract type vs churn\n",
    "ax = axes[1, 0]\n",
    "contract_churn = df_viz.groupby('contract_type')['churn'].mean()\n",
    "contract_labels = ['Month-to-month', 'One year', 'Two year']\n",
    "ax.bar(contract_labels, contract_churn.values, color='steelblue')\n",
    "ax.set_title('Churn Rate by Contract Type', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Churn Rate')\n",
    "for i, v in enumerate(contract_churn.values):\n",
    "    ax.text(i, v + 0.02, f'{v:.1%}', ha='center')\n",
    "\n",
    "# Support calls vs churn\n",
    "ax = axes[1, 1]\n",
    "support_churn = df_viz.groupby('support_calls')['churn'].mean()\n",
    "ax.bar(support_churn.index, support_churn.values, color='coral')\n",
    "ax.set_title('Churn Rate by Support Calls', fontsize=12, fontweight='bold')\n",
    "ax.set_xlabel('Number of Support Calls')\n",
    "ax.set_ylabel('Churn Rate')\n",
    "\n",
    "# Tech support vs churn\n",
    "ax = axes[1, 2]\n",
    "tech_churn = df_viz.groupby('has_tech_support')['churn'].mean()\n",
    "ax.bar(['No Tech Support', 'Has Tech Support'], tech_churn.values, color=['coral', 'steelblue'])\n",
    "ax.set_title('Churn Rate by Tech Support', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Churn Rate')\n",
    "for i, v in enumerate(tech_churn.values):\n",
    "    ax.text(i, v + 0.02, f'{v:.1%}', ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey Observations:\")\n",
    "print(f\"- Month-to-month contracts have {contract_churn[0]:.1%} churn vs {contract_churn[2]:.1%} for two-year\")\n",
    "print(f\"- Customers without tech support churn at {tech_churn[0]:.1%} vs {tech_churn[1]:.1%} with support\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## Step 4: Prepare Data for SageMaker XGBoost\n",
    "\n",
    "SageMaker's XGBoost algorithm expects data in CSV format:\n",
    "- **Training**: Label in the first column, followed by features (no header)\n",
    "- **Inference**: Features only (no label column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create local data directory\n",
    "os.makedirs('data', exist_ok=True)\n",
    "\n",
    "def save_csv_for_training(X, y, filepath):\n",
    "    \"\"\"Save data in SageMaker XGBoost CSV format (label first, no header).\"\"\"\n",
    "    data = np.column_stack([y.reshape(-1, 1), X])\n",
    "    np.savetxt(filepath, data, delimiter=',', fmt='%.6f')\n",
    "\n",
    "def save_csv_for_inference(X, filepath):\n",
    "    \"\"\"Save features only for batch transform inference.\"\"\"\n",
    "    np.savetxt(filepath, X, delimiter=',', fmt='%.6f')\n",
    "\n",
    "# Save training data (label + features)\n",
    "save_csv_for_training(X_train, y_train, 'data/train.csv')\n",
    "\n",
    "# Save test features only (for batch transform)\n",
    "save_csv_for_inference(X_test, 'data/test_features.csv')\n",
    "\n",
    "# Save test labels locally for evaluation\n",
    "np.savetxt('data/test_labels.csv', y_test, delimiter=',', fmt='%.0f')\n",
    "\n",
    "print(\"Data saved locally:\")\n",
    "print(f\"  - data/train.csv ({os.path.getsize('data/train.csv') / 1024:.1f} KB)\")\n",
    "print(f\"  - data/test_features.csv ({os.path.getsize('data/test_features.csv') / 1024:.1f} KB)\")\n",
    "print(f\"  - data/test_labels.csv ({os.path.getsize('data/test_labels.csv') / 1024:.1f} KB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the data format\n",
    "print(\"Sample training data (first 3 rows):\")\n",
    "print(\"Format: label, feature1, feature2, ..., feature11\")\n",
    "print(\"=\"*70)\n",
    "with open('data/train.csv', 'r') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i >= 3:\n",
    "            break\n",
    "        print(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload to S3\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "train_s3_path = f\"{PREFIX}/train/train.csv\"\n",
    "test_s3_path = f\"{PREFIX}/test/test_features.csv\"\n",
    "\n",
    "s3_client.upload_file('data/train.csv', BUCKET_NAME, train_s3_path)\n",
    "s3_client.upload_file('data/test_features.csv', BUCKET_NAME, test_s3_path)\n",
    "\n",
    "train_s3_uri = f\"s3://{BUCKET_NAME}/{train_s3_path}\"\n",
    "test_s3_uri = f\"s3://{BUCKET_NAME}/{test_s3_path}\"\n",
    "\n",
    "print(\"Data uploaded to S3:\")\n",
    "print(f\"  Train: {train_s3_uri}\")\n",
    "print(f\"  Test:  {test_s3_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "## Step 5: Configure and Train the XGBoost Model\n",
    "\n",
    "### Key Hyperparameters\n",
    "\n",
    "**objective** (Required)\n",
    "- Specifies the learning task and loss function\n",
    "- `binary:logistic`: Binary classification, outputs probability\n",
    "- `multi:softmax`: Multiclass classification, outputs class\n",
    "- `reg:squarederror`: Regression with squared error loss\n",
    "\n",
    "**num_round** (Required)\n",
    "- Number of boosting rounds (trees to build)\n",
    "- More rounds can improve accuracy but risk overfitting\n",
    "- Typical range: 50-500, use early stopping to find optimal\n",
    "\n",
    "**max_depth**\n",
    "- Maximum depth of each tree\n",
    "- Controls model complexity and overfitting\n",
    "- Deeper trees can capture more complex patterns but overfit more easily\n",
    "- Typical range: 3-10 (default: 6)\n",
    "\n",
    "**eta (learning_rate)**\n",
    "- Step size shrinkage to prevent overfitting\n",
    "- Lower values require more boosting rounds but generalize better\n",
    "- Typical range: 0.01-0.3 (default: 0.3)\n",
    "\n",
    "**subsample**\n",
    "- Fraction of training samples used per tree\n",
    "- Adds randomness to prevent overfitting (like bagging)\n",
    "- Typical range: 0.5-1.0 (default: 1.0)\n",
    "\n",
    "**colsample_bytree**\n",
    "- Fraction of features used per tree\n",
    "- Adds randomness and can improve generalization\n",
    "- Typical range: 0.5-1.0 (default: 1.0)\n",
    "\n",
    "**min_child_weight**\n",
    "- Minimum sum of instance weight needed in a child node\n",
    "- Higher values prevent learning overly specific patterns\n",
    "- For classification, this is the minimum number of samples\n",
    "- Typical range: 1-10 (default: 1)\n",
    "\n",
    "**gamma (min_split_loss)**\n",
    "- Minimum loss reduction required to make a split\n",
    "- Acts as regularization: higher values = more conservative\n",
    "- Typical range: 0-5 (default: 0)\n",
    "\n",
    "**alpha (reg_alpha)**\n",
    "- L1 regularization on leaf weights\n",
    "- Encourages sparsity (many zero weights)\n",
    "- Useful for high-dimensional data\n",
    "\n",
    "**lambda (reg_lambda)**\n",
    "- L2 regularization on leaf weights\n",
    "- Smooths weights, reduces overfitting\n",
    "- Default: 1\n",
    "\n",
    "**scale_pos_weight**\n",
    "- Balance the positive and negative class weights\n",
    "- For imbalanced datasets, set to: sum(negative) / sum(positive)\n",
    "- Helps the model pay more attention to the minority class\n",
    "\n",
    "**eval_metric**\n",
    "- Metric used for validation and early stopping\n",
    "- `auc`: Area under ROC curve (good for imbalanced data)\n",
    "- `error`: Classification error rate\n",
    "- `logloss`: Negative log-likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the XGBoost container image\n",
    "xgboost_image = retrieve(\n",
    "    framework='xgboost',\n",
    "    region=region,\n",
    "    version='1.5-1'  # Use a stable version\n",
    ")\n",
    "\n",
    "print(f\"XGBoost Image URI: {xgboost_image}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the estimator\n",
    "xgboost_estimator = Estimator(\n",
    "    image_uri=xgboost_image,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.large',\n",
    "    output_path=f's3://{BUCKET_NAME}/{PREFIX}/output',\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    base_job_name='xgboost-churn'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate scale_pos_weight for imbalanced data\n",
    "# This helps the model pay more attention to the minority class (churn)\n",
    "num_negative = (y_train == 0).sum()\n",
    "num_positive = (y_train == 1).sum()\n",
    "scale_pos_weight = num_negative / num_positive\n",
    "\n",
    "print(f\"Class distribution: {num_negative} negative, {num_positive} positive\")\n",
    "print(f\"Calculated scale_pos_weight: {scale_pos_weight:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyperparameters\n",
    "hyperparameters = {\n",
    "    # Objective and evaluation\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"eval_metric\": \"auc\",\n",
    "    \n",
    "    # Number of boosting rounds\n",
    "    \"num_round\": 100,\n",
    "    \n",
    "    # Tree parameters\n",
    "    \"max_depth\": 5,\n",
    "    \"eta\": 0.1,                    # Learning rate\n",
    "    \"min_child_weight\": 3,\n",
    "    \"gamma\": 0.1,                  # Min split loss\n",
    "    \n",
    "    # Sampling parameters (regularization)\n",
    "    \"subsample\": 0.8,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \n",
    "    # Regularization\n",
    "    \"alpha\": 0.1,                  # L1 regularization\n",
    "    \"lambda\": 1.0,                 # L2 regularization\n",
    "    \n",
    "    # Handle class imbalance\n",
    "    \"scale_pos_weight\": scale_pos_weight,\n",
    "}\n",
    "\n",
    "xgboost_estimator.set_hyperparameters(**hyperparameters)\n",
    "\n",
    "print(\"Hyperparameters configured:\")\n",
    "for k, v in hyperparameters.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training input\n",
    "train_input = TrainingInput(\n",
    "    s3_data=train_s3_uri,\n",
    "    content_type='text/csv'\n",
    ")\n",
    "\n",
    "print(\"Starting training job...\")\n",
    "print(\"This will take approximately 3-5 minutes.\\n\")\n",
    "\n",
    "# Start training\n",
    "xgboost_estimator.fit({'train': train_input}, wait=True, logs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training job info\n",
    "training_job_name = xgboost_estimator.latest_training_job.name\n",
    "print(f\"Training job completed: {training_job_name}\")\n",
    "print(f\"Model artifacts: {xgboost_estimator.model_data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "## Step 6: Run Batch Transform\n",
    "\n",
    "Instead of deploying a real-time endpoint, we use Batch Transform for predictions on the test set. This is more cost-effective for batch predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create transformer from the trained model\n",
    "transformer = xgboost_estimator.transformer(\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.large',\n",
    "    output_path=f's3://{BUCKET_NAME}/{PREFIX}/batch-predictions'\n",
    ")\n",
    "\n",
    "print(\"Starting batch transform job...\")\n",
    "print(\"This will take approximately 3-5 minutes.\\n\")\n",
    "\n",
    "# Run batch inference\n",
    "transformer.transform(\n",
    "    data=test_s3_uri,\n",
    "    content_type='text/csv',\n",
    "    split_type='Line',\n",
    "    wait=True\n",
    ")\n",
    "\n",
    "print(f\"\\nPredictions written to: {transformer.output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "## Step 7: Download and Parse Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download predictions from S3\n",
    "prediction_key = f\"{PREFIX}/batch-predictions/test_features.csv.out\"\n",
    "\n",
    "s3_client.download_file(BUCKET_NAME, prediction_key, 'data/predictions.csv')\n",
    "\n",
    "# Load predictions (XGBoost outputs probabilities for binary:logistic)\n",
    "y_pred_proba = np.loadtxt('data/predictions.csv')\n",
    "y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "\n",
    "print(f\"Loaded predictions for {len(y_pred)} samples\")\n",
    "print(f\"Prediction distribution: {np.bincount(y_pred)}\")\n",
    "print(f\"Probability range: [{y_pred_proba.min():.4f}, {y_pred_proba.max():.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-25",
   "metadata": {},
   "source": [
    "## Step 8: Evaluate Model Performance\n",
    "\n",
    "### Understanding Classification Metrics\n",
    "\n",
    "**Accuracy**\n",
    "- Percentage of correct predictions\n",
    "- Can be misleading with imbalanced classes\n",
    "- If 90% of customers don't churn, predicting \"no churn\" for everyone gives 90% accuracy!\n",
    "\n",
    "**Precision**\n",
    "- Of all customers predicted to churn, how many actually churned?\n",
    "- High precision = few false alarms\n",
    "- Important when the cost of intervention is high\n",
    "\n",
    "**Recall (Sensitivity)**\n",
    "- Of all customers who actually churned, how many did we catch?\n",
    "- High recall = we catch most churners\n",
    "- Important when missing a churner is costly\n",
    "\n",
    "**F1 Score**\n",
    "- Harmonic mean of precision and recall\n",
    "- Balances both metrics\n",
    "- Useful when you need a single metric for imbalanced data\n",
    "\n",
    "**AUC-ROC**\n",
    "- Area Under the Receiver Operating Characteristic curve\n",
    "- Measures discrimination ability across all thresholds\n",
    "- 0.5 = random guessing, 1.0 = perfect\n",
    "- Good for imbalanced datasets\n",
    "\n",
    "**Confusion Matrix**\n",
    "- Shows True Positives (TP), False Positives (FP), True Negatives (TN), False Negatives (FN)\n",
    "- Helps understand which types of errors the model makes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, confusion_matrix, classification_report,\n",
    "    roc_curve, precision_recall_curve, average_precision_score\n",
    ")\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "avg_precision = average_precision_score(y_test, y_pred_proba)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"MODEL EVALUATION RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nAccuracy:           {accuracy:.4f}\")\n",
    "print(f\"Precision:          {precision:.4f}\")\n",
    "print(f\"Recall:             {recall:.4f}\")\n",
    "print(f\"F1 Score:           {f1:.4f}\")\n",
    "print(f\"ROC AUC:            {auc:.4f}\")\n",
    "print(f\"Average Precision:  {avg_precision:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CLASSIFICATION REPORT\")\n",
    "print(\"=\"*60)\n",
    "print(classification_report(y_test, y_pred, target_names=['No Churn', 'Churn']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"CONFUSION MATRIX\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nTrue Negatives (correct no-churn):  {tn}\")\n",
    "print(f\"False Positives (false alarm):       {fp}\")\n",
    "print(f\"False Negatives (missed churn):      {fn}\")\n",
    "print(f\"True Positives (caught churn):       {tp}\")\n",
    "\n",
    "print(f\"\\nSpecificity (TN rate):  {tn / (tn + fp):.4f}\")\n",
    "print(f\"False Positive Rate:    {fp / (tn + fp):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "\n",
    "# 1. Confusion Matrix Heatmap\n",
    "ax = axes[0, 0]\n",
    "im = ax.imshow(cm, cmap='Blues')\n",
    "ax.set_xticks([0, 1])\n",
    "ax.set_yticks([0, 1])\n",
    "ax.set_xticklabels(['No Churn', 'Churn'])\n",
    "ax.set_yticklabels(['No Churn', 'Churn'])\n",
    "ax.set_xlabel('Predicted', fontsize=12)\n",
    "ax.set_ylabel('Actual', fontsize=12)\n",
    "ax.set_title('Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax.text(j, i, str(cm[i, j]), ha='center', va='center', fontsize=20, fontweight='bold')\n",
    "plt.colorbar(im, ax=ax)\n",
    "\n",
    "# 2. ROC Curve\n",
    "ax = axes[0, 1]\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "ax.plot(fpr, tpr, 'b-', linewidth=2, label=f'XGBoost (AUC = {auc:.3f})')\n",
    "ax.plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random')\n",
    "ax.fill_between(fpr, tpr, alpha=0.2)\n",
    "ax.set_xlabel('False Positive Rate', fontsize=12)\n",
    "ax.set_ylabel('True Positive Rate', fontsize=12)\n",
    "ax.set_title('ROC Curve', fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='lower right')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Precision-Recall Curve\n",
    "ax = axes[1, 0]\n",
    "precision_curve, recall_curve, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "ax.plot(recall_curve, precision_curve, 'b-', linewidth=2, label=f'XGBoost (AP = {avg_precision:.3f})')\n",
    "ax.axhline(y=y_test.mean(), color='k', linestyle='--', linewidth=1, label=f'Baseline ({y_test.mean():.2f})')\n",
    "ax.fill_between(recall_curve, precision_curve, alpha=0.2)\n",
    "ax.set_xlabel('Recall', fontsize=12)\n",
    "ax.set_ylabel('Precision', fontsize=12)\n",
    "ax.set_title('Precision-Recall Curve', fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='lower left')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Prediction Distribution\n",
    "ax = axes[1, 1]\n",
    "ax.hist(y_pred_proba[y_test == 0], bins=50, alpha=0.6, label='No Churn (Actual)', color='steelblue', density=True)\n",
    "ax.hist(y_pred_proba[y_test == 1], bins=50, alpha=0.6, label='Churn (Actual)', color='coral', density=True)\n",
    "ax.axvline(x=0.5, color='black', linestyle='--', linewidth=2, label='Threshold (0.5)')\n",
    "ax.set_xlabel('Predicted Churn Probability', fontsize=12)\n",
    "ax.set_ylabel('Density', fontsize=12)\n",
    "ax.set_title('Prediction Distribution', fontsize=14, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-29",
   "metadata": {},
   "source": [
    "## Step 9: Threshold Analysis\n",
    "\n",
    "The default threshold of 0.5 may not be optimal for your business case. Let's analyze how different thresholds affect precision and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze different thresholds\n",
    "thresholds = np.linspace(0.1, 0.9, 17)\n",
    "results = []\n",
    "\n",
    "for thresh in thresholds:\n",
    "    y_pred_thresh = (y_pred_proba >= thresh).astype(int)\n",
    "    results.append({\n",
    "        'threshold': thresh,\n",
    "        'precision': precision_score(y_test, y_pred_thresh, zero_division=0),\n",
    "        'recall': recall_score(y_test, y_pred_thresh, zero_division=0),\n",
    "        'f1': f1_score(y_test, y_pred_thresh, zero_division=0),\n",
    "        'predicted_positive': y_pred_thresh.sum()\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Find optimal thresholds\n",
    "best_f1_idx = results_df['f1'].idxmax()\n",
    "best_f1_thresh = results_df.loc[best_f1_idx, 'threshold']\n",
    "\n",
    "print(\"Threshold Analysis:\")\n",
    "print(results_df.to_string(index=False))\n",
    "print(f\"\\nOptimal threshold for F1 score: {best_f1_thresh:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize threshold trade-offs\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "ax.plot(results_df['threshold'], results_df['precision'], 'b-', linewidth=2, marker='o', label='Precision')\n",
    "ax.plot(results_df['threshold'], results_df['recall'], 'r-', linewidth=2, marker='s', label='Recall')\n",
    "ax.plot(results_df['threshold'], results_df['f1'], 'g-', linewidth=2, marker='^', label='F1 Score')\n",
    "ax.axvline(x=0.5, color='gray', linestyle='--', alpha=0.7, label='Default (0.5)')\n",
    "ax.axvline(x=best_f1_thresh, color='green', linestyle=':', linewidth=2, label=f'Best F1 ({best_f1_thresh:.2f})')\n",
    "\n",
    "ax.set_xlabel('Classification Threshold', fontsize=12)\n",
    "ax.set_ylabel('Score', fontsize=12)\n",
    "ax.set_title('Precision-Recall Trade-off by Threshold', fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='center right')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_xlim(0.05, 0.95)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nBusiness Considerations:\")\n",
    "print(\"- Lower threshold: Catch more churners (high recall) but more false alarms (low precision)\")\n",
    "print(\"- Higher threshold: Fewer false alarms (high precision) but miss more churners (low recall)\")\n",
    "print(\"- Choose based on: cost of intervention vs cost of losing a customer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-32",
   "metadata": {},
   "source": [
    "## Step 10: Deploy Model (Optional)\n",
    "\n",
    "If you need real-time predictions, you can deploy the model to an endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to deploy the model\n",
    "# WARNING: This will incur ongoing charges until deleted!\n",
    "\n",
    "# print(\"Deploying model to endpoint...\")\n",
    "# print(\"This will take approximately 5-7 minutes.\\n\")\n",
    "\n",
    "# predictor = xgboost_estimator.deploy(\n",
    "#     initial_instance_count=1,\n",
    "#     instance_type='ml.m5.large',\n",
    "#     endpoint_name=f'xgboost-churn-endpoint-{datetime.now().strftime(\"%Y%m%d%H%M\")}'\n",
    "# )\n",
    "\n",
    "# print(f\"\\nEndpoint deployed: {predictor.endpoint_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Make predictions with deployed endpoint\n",
    "# Uncomment if you deployed the model above\n",
    "\n",
    "# from sagemaker.serializers import CSVSerializer\n",
    "# from sagemaker.deserializers import CSVDeserializer\n",
    "\n",
    "# predictor.serializer = CSVSerializer()\n",
    "# predictor.deserializer = CSVDeserializer()\n",
    "\n",
    "# # Make prediction for a single customer\n",
    "# sample_customer = X_test[0:1]\n",
    "# result = predictor.predict(sample_customer)\n",
    "# print(f\"Churn probability: {float(result[0][0]):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete endpoint when done\n",
    "# Uncomment if you deployed the model\n",
    "\n",
    "# print(f\"Deleting endpoint: {predictor.endpoint_name}\")\n",
    "# predictor.delete_endpoint()\n",
    "# print(\"Endpoint deleted successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-36",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "In this exercise, you learned:\n",
    "\n",
    "1. **Data Format**: SageMaker XGBoost expects CSV format with the label in the first column (no header)\n",
    "\n",
    "2. **Key Hyperparameters**:\n",
    "   - `objective`: Learning task (binary:logistic for binary classification)\n",
    "   - `num_round`: Number of boosting rounds\n",
    "   - `max_depth`: Tree depth (controls complexity)\n",
    "   - `eta`: Learning rate (lower = more regularization)\n",
    "   - `scale_pos_weight`: Handles class imbalance\n",
    "\n",
    "3. **Evaluation Metrics**:\n",
    "   - Use AUC-ROC for imbalanced datasets (more robust than accuracy)\n",
    "   - Consider precision vs recall trade-off based on business needs\n",
    "   - Tune threshold based on cost of false positives vs false negatives\n",
    "\n",
    "4. **Best Practices**:\n",
    "   - Use Batch Transform for cost-effective batch predictions\n",
    "   - Set `scale_pos_weight` for imbalanced classification\n",
    "   - Use regularization (`alpha`, `lambda`, `subsample`) to prevent overfitting\n",
    "   - Always delete endpoints when done to avoid charges\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Experiment with different hyperparameters\n",
    "- Try SageMaker Hyperparameter Tuning for automatic optimization\n",
    "- Add validation data for early stopping\n",
    "- Use SHAP values to explain individual predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aws-ml-engineer-exercises",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
